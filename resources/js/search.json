[[{"l":"Baselime Documentation","p":["To get started, read the quick start guide.","This documentation highlights what Baselime is, how to get it working with your stack and how it can help you discover, investigate, and resolve errors faster.","Quick Start Baselime Documentation Analyzing Data in Baselime Baselime CLI Observability as Code Data Security"]},{"l":"Support","p":["Join the Baselime Slack Community if you have any questions, or you want to learn and discuss ideas around observability practices."]}],[{"i":"what-is-baselime","l":"What is Baselime?","p":["Baselime is an observability solution built for modern cloud-native environments. It combines logs, metrics, and distributed traces to give you full visibility across your microservices at scale.","Baselime Console"]},{"i":"how-is-baselime-different","l":"How is Baselime different?","p":["Baselime is fundamentally different from most other observability and monitoring providers in 4 key aspects:"]},{"l":"High cardinality and dimentionality","p":["Cardinality and dimentionality are best described using examples. Imagine you log an HTTP request that makes database calls.","High cardinality means that in your logs, you can have a unique userId or requestId(which can take over a million distinct values). Those are high cardinality fields. Baselime enables you to query against any specific value of a high cardinality field so that you can narrow down your search to a specific user or request.","High dimensionality means that in your logs, you can have thousands of possible fields. You can record each HTTP header of your request and the details of each database call. Any log can be a key-value object with thousands of individual keys. Baselime indexes every single one of the keys and enables you to query against every one of them.","From day 0, everything is queriable and searchable, and correlation between data sources is possible. Baselime does not perform any pre-aggregation of data before ingestion; this means you can run arbitrary queries on you telemetry data, and get answers about the state of your application."]},{"l":"Query speed","p":["Baselime is built on top of ClickHouse, the fastest analytics database in the world. When debugging real production outages, the ability to ask questions and get answers fast is most important."]},{"l":"Real-time data ingestion","p":["Baselime ingests data from your application in real-time. Telemetry data is available for you to query or for the real-time alerting within seconds of it being generated by your applications."]},{"l":"Metadata annotations","p":["Baselime automatically adds all the metadata necessary to contextualise your telemetry data: hostname, hostID, serverless function name, service name, cloud account and region, etc. All this data is automatically captured by Baselime. It enables you to efficiently identify patterns based on those parameters automatically.","Moreover, Baselime gives your control over the residency of your data. Either using our backend or a Bring Your Own Backend solution where all the data is stored on your cloud account."]},{"i":"why-baselime","l":"Why Baselime?"},{"l":"Find and solve issues faster","p":["Troubleshoot infrastructure and application issues with high cardinality data and a fast query enginer."]},{"i":"search-anything-anywhere-its-all-indexed","l":"Search anything, anywhere. It's all indexed","p":["Query against any nested field and automatically surface anomalies fast; regardless of how unusual or unique this state of your application is."]},{"l":"Take control of your data and costs","p":["Use or backend or Bring Your Own Backend. Up to 6x more value than incumbents. No per-function pricing, no per-seat pricing, no per-alert pricing. Start at $0 and scale up as your applications grow, with no hidden fees."]}],[{"l":"FAQ"},{"i":"what-is-baselime","l":"What is Baselime?","p":["Baselime is an observability solution that makes observability for cloud-native microservices easy. Baselime covers your logs, metrics, traces in a single solution. Baselime is built on top of ClickHouse, the fastest columnar database in the world."]},{"i":"how-much-does-it-cost","l":"How much does it cost?","p":["Baselime pricing is based on the number of events your systems produce. This scales linearly with the traffic your applications handle. Moreover, Baselime has a full free tier for up to 4M events per month.","Check out our pricing page for more details."]},{"i":"how-does-baselime-count-events-for-billing","l":"How does Baselime count events for billing?","p":["Baselime counts the number of events daily and updates your dashboard accordingly. Baselime does not count Amazon CloudWatch metrics or Amazon CloudTrail logs as part of the monthly event cap. All other events are counted, include the START, END and REPORT log lines from serverless functions."]},{"i":"does-baselime-support-containers","l":"Does Baselime support containers?","p":["Baselime works with any environment where OpenTelemetry is available. Moreover, Baselime provides an HTTP API where you can send events individually from environments where OpenTelemetry is not available.","Baselime has a native integration with container platforms on AWS:","Amazon ECS (Fargate and EC2)","Amazon AppRunner","These integration enable logs, metrics and traces generated without OpenTelemetry to be automatically ingested into Baselime."]},{"i":"does-baselime-support-multi-accounts-and-multi-regions","l":"Does Baselime support multi-accounts and multi-regions?","p":["Yes, Baselime supports for multi-account and multi-region setups. When you connect your first cloud account to Baselime, Baselime creats a Baselime environment. You can subsequently add as many new cloud accounts or regions to the Baselime environment. All your telemetry data from those separate accounts and regions will be unified in the Baselime environment."]},{"i":"how-easy-is-it-to-instrument-my-aws-applications","l":"How easy is it to instrument my AWS applications?","p":["When you connect your AWS account to Baselime, logs from your AWS Lambda functions, API Gateways and AppRunner services, and metrics from your entire AWS account are automatically ingested into Baselime. No further setup is required.","When you connect your Vercel account to Baselime, all your Vercel application logs, edge function logs and build logs are ingested into Baselime. No further setup is required.","Moreover, if you have Amazon X-Ray enabled on your services (both serverless functions and containers), these traces are automatically ingested into Baselime.","To use OpenTelemetry distributed tracing, add the baselime:tracing tag to your AWS Lambda functions using the Node.js runtime and these will be automatically instrumented. We're currently working on more runtimes.","For any other runtimes or environments, instrument your applications with OpenTelemetry or send your logs via the HTTP API."]},{"i":"how-easy-is-it-to-instrument-my-vercel-applications","l":"How easy is it to instrument my Vercel applications?","p":["When you connect your Vercel account to Baselime, all your Vercel application logs, edge function logs and build logs are ingested into Baselime. No further setup is required."]},{"i":"how-do-i-get-distributed-tracing","l":"How do I get distributed tracing?","p":["Baselime supports both OpenTelemetry and AWS X-Ray for distributed tracing. If you application is already instrumented with OpenTelemetry, change the destination of your instrumetation to the Baselime endpoint:","URL: https://otel.baselime.io/v1","Header: x-api-key: BASELIME_API_KEY","Alternatively, you can instrument your AWS Lambda function with the Baselime OpenTelemetry tracer. Add the baselime:tracing tag to your AWS Lambda functions, and set it to true.","The automatic OpenTelemetry tracing with the tag is available for Node.js AWS Lambda functions, we're currently working on enabling this for other runtimes.","If you use AWS X-Ray, Baselime automatically capture traces from X-Ray when your AWS Account is connected."]},{"i":"how-hard-is-it-to-remove-baselime-from-my-aws-account","l":"How hard is it to remove Baselime from my AWS account?","p":["If you decide to remove Baselime from your AWS account, delete the CloudFormation template Baselime creates on your AWS account. That's all, all resources Baselime created, including the instrumentation layers, will be removed."]},{"i":"does-baselime-automatically-recognise-new-functions-and-services","l":"Does Baselime automatically recognise new functions and services?","p":["Yes, when you deploy new serverless functions and services to your cloud infrastructure, Baselime automatically detects them and starts ingesting logs, metrics and traces from those function. To add OpenTelemetry tracing, add the baselime:tracing tag to your new functions and set it to true."]},{"i":"where-is-my-data-stored","l":"Where is my data stored?","p":["You own your data.","You can select to use either our cloud offering, or our Bring Your Own Backend solution. With Bring Your Own Backend, all the data is stored on your AWS account and your use the Baselime clients to access it."]},{"l":"Cloud offering","p":["All the telemetry data your cloud infrastructure generate is stored in two data tiers:","hot tier: on Baselime AWS accounts in the eu-west-1 region. This data is used for fast questions","cold tier: in an Amazon S3 bucket in your AWS cloud account. This data is used for long terms storage in a resource you own","It is possible to rehydrate data from the cold tier to the hot tier for queriyng historical incidents free of charge."]},{"l":"Bring Your Own Backend","p":["Baselime can integrate with your own backend. As such, all the telemetry data is stored and queried in your cloud account. The enables you to keep maximum flexibility and privacy for storing sensitive data. You will be able to set your own retention periods, your own storage type, and your own privacy settings.","Bring Your Own Backend is available on our Enterprise Plans."]},{"i":"is-my-data-secure","l":"Is my data secure?","p":["Baselime is fully GDPR compliant and your data is stored in data centers that are all SOC2 compliant."]},{"i":"how-can-i-work-with-my-team","l":"How can I work with my team?","p":["Once you sign up to Baselime with your organisation domain email, you can configure Baselime such that anyone with the same email domain can join your workspace.","Moreover, you can invite your teammates individurally. Additionally, every query result, dashboards, an alerts have a unique permalink in Baselime that you can share with your team."]},{"i":"does-baselime-have-an-impact-on-my-aws-bill","l":"Does Baselime have an impact on my AWS bill?","p":["Baselime relies on a few AWS resources in your AWS account, most notably:","Amazon CloudWatch metrics stream: to enable CloudWatch metrics to be queried using the Baselime query engine","Amazon CloudTrail: to enable CloudTrail events, and also register new subscription filters as soon as new serverless functions or services are created","Amazon Kinesis Data Firehose: To store telemetry data in cold storage in your AWS account","These services may add a minimal cost on your AWS monthly bill. Please refer to the AWS princing calculator for estimates based on your usage."]},{"i":"does-baselime-have-an-impact-on-my-vercel-bill","l":"Does Baselime have an impact on my Vercel bill?","p":["No, Baselime doesn't have any impact on your Vercel bill."]}],[{"l":"Quick Start Guide"},{"i":"step-1-sign-up-for-baselime","l":"Step 1: Sign up for Baselime","p":["You can sign up for a free Baselime account here."]},{"i":"step-2-add-an-environment","l":"Step 2: Add an Environment","p":["You can add an environment by connecting your cloud account, or by creating an environment manually to send data manually to Baselime.","Add an Environment"]},{"i":"step-3-send-a-log-event-optional","l":"Step 3: Send a log event (optional)","p":["If you created an environment manually, execute this cURL command to send your first log event to Baselime.","Replace your BASELIME_API_KEY with the API key your got from step 2."]},{"i":"step-4-explore-your-data","l":"Step 4: Explore your data","p":["Congratulations! Your first event should be available to query in Baselime. You can start exploring your data using the Baselime console, the Baselime CLI or any other of our clients.","View of an AWS Lambda function in Baselime"]},{"l":"Guides","p":["Sending Data: Learn how to ingest telemetry data from your cloud-native applications","Analyzing Data: Discover how to use the various interfaces provided by Baselime to analyze and understand your data"]},{"l":"Reference","p":["Baselime CDK Reference Guide: Learn about how to use Baselime with the AWS CDK to define your Observability as Code","CLI Reference: Complete reference for the Baselime command-line interface"]},{"l":"Community","p":["Join the Baselime community to get help with using the platform, share your own experiences, and stay up-to-date with the latest developments.","Slack: Join our Slack community to connect with other Baselime users and get real-time support from the Baselime team","Blog: Read about the latest features, best practices, and more from the Baselime team","Social media: Follow us on Twitter, LinkedIn, and YouTube to stay up-to-date with the latest news and updates from Baselime","We look forward to connecting with you!"]}],[{"l":"Sending Data to Baselime","p":["Baselime supports a variety of data sources, including logs, metrics, traces, and wide events. You can start sending your data to Baselime and gain valuable insights into the performance and reliability of your microservices with a few steps."]},{"l":"Data Sources"},{"l":"OpenTelemetry","p":["Sending Data to Baselime"]},{"l":"Vercel","p":["Sending Data to Baselime"]},{"l":"Cloudflare","p":["Sending Data to Baselime"]},{"l":"AWS","p":["Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime"]},{"l":"Other Sources","p":["Sending Data to Baselime Sending Data to Baselime"]}],[{"l":"OpenTelemetry","p":["If your codebase is already instrumented with OpenTelemetry, you can start sending your tracing data to Baselime today.","Add the Baselime OpenTelemetry endpoint to your exporter:","Endpoint https://otel.baselime.io/v1/","Header: x-api-key: BASELIME_API_KEY","You can get your public Baselime API key in the Baselime console from the Baselime CLI.","If you have not instrumented your codebase with OpenTelemetry yet, we are building OpenTelemetry SDKs to facilitate instrumenting your code."]},{"l":"OpenTelemetry SDKs","p":["OpenTelemetry"]},{"l":"OpenTelemetry on AWS Lambda","p":["OpenTelemetry"]}],[{"i":"opentelemetry-for-nodejs","l":"OpenTelemetry for Node.js","p":["The Baselime Node.js OpenTelemetry SDK enables you to instrument your Node.js services with OpenTelemetry without the boilerplate of using the OpenTelemetry SDK directly.","This SDK uses OpenTelemetry for JavaScript and provides a layer that facilitates instrumenting your Node.js applications.","If your application is already instrumented with OpenTelemetry, you can start sending your tracing data to Baselime without any additional code changes.","Add the Baselime OpenTelemetry endpoint to your exporter:","Endpoint https://otel.baselime.io/v1/","Header: x-api-key: BASELIME_API_KEY"]},{"l":"Instrumentation"},{"i":"step-1-install-the-sdks","l":"Step 1: Install the SDKs","p":["Install the Baselime Node.js OpenTelemetry SDK."]},{"i":"step-2-initialise-the-tracer","l":"Step 2: Initialise the tracer","p":["Create a tracing.cjs file inside your application working directory."]},{"i":"step-3-set-the-baselime-environment-variables","l":"Step 3: Set the Baselime environment variables","p":["Set the environment variables of your comntainer service to include the Baselime API Key and set the NODE_OPTIONS enviroment variable to preload the OpenTelemetry SDK into your application.","Key","Value","Description","BASELIME_KEY","your-api-key","Get this key from the Baselime console or the Baselime CLI","NODE_OPTIONS","-r ./src/tracing.cjs --experimental-loader=import-in-the-middle/hook.mjs","Preloads the OpenTelemetry SDK at startup","Once these steps are completed, distributed traces from your Node.js container applications should be available in Baselime to query via the console or the Baselime CLI.","Example OpenTelemetry Trace"]},{"l":"Configuration","p":["An array of instrumentation options","baselimeKey","collectorUrl","Description","Field","InstrumentationOption[]","instrumentations","namespace","service","string(optional)","The Baselime API key","The BaselimeSDK class of the Baselime Node.js OpenTelemetry SDK takes the following configuration options.","The namespace","The service name","The URL of the collector","Type"]}],[{"i":"opentelemetry-for-nodejs-on-aws-lambda","l":"OpenTelemetry for Node.js on AWS Lambda","p":["The Baselime Node.js OpenTelemetry tracer for AWS Lambda instruments your Node.js AWS Lambda functions with OpenTelemetry and automatically sends OpenTelemetry traces to Baselime. This is the most powerful and flexible way to instrument your Node.js AWS Lambda functions."]},{"l":"Automatic Instrumentation","p":["To automatically instrument your AWS Lambda functions with the Baselime Node.js OpenTelemetry tracer for AWS Lambda, set the following tag to your AWS Lambda functions: baselime:tracing=true.","To add the Baselime tag to all your AWS Lambda functions in a service or stack add this line to your AWS CDK code.","To add the Baselime tag to all your AWS Lambda functions in a service or stack add this line to your sst.config.ts file.","To add the Baselime tag to all your AWS Lambda functions in a add this snippet to your serverless.yml file.","To add the Baselime tag to all your AWS Lambda functions in a add this snippet to your AWS SAM configuration file.","That's all you are all set with OpenTelemetry on Node.js AWS Lambda functions.","OpenTelemetry automatic instrumentation is available only once you have connected your AWS Account to Baselime. Adding the tag to AWS Lambda functions in an AWS Account not connected to Baselime will not have any effect.","We recommended a miminum of 512mb of memory configured on AWS Lambda functions with the automatic OpenTelemetry instrumentation. AWS Lambda functions with less memory may experience higher latencies as the traces are being processed.","To remove the OpenTelemetry instrumentation from your AWS Lambda functions, remove the baselime:tracing=true tag from the function and Baselime will revert the function to un-instrumentate state.","Other observability tool layers and tags can adversely interact with the Baselime OpenTelemetry layer. We recommend to disable all other observability layers and tags before instrumenting your AWS Lambda functions with the Baselime OpenTelemetry layer. Failing to do so could result in down-time."]},{"l":"Adding custom OpenTelemetry spans","p":["To add custom spans to your OpenTelemetry traces, install the @opentelemetry/api package.","And manually add spans to your traces."]},{"l":"Sending data to another OpenTelemetry backend","p":["OpenTelemetry is an open standard, and you can use the Baselime Node.js OpenTelemetry tracer for AWS Lambda to send telemetry data to another backend of your choice.","Set environment variable COLLECTOR_URL to your observability backend."]},{"l":"Limitations","p":["The AWS JS SDK v2 can result in errors when interacting with OpenTelemetry during automatic request retries. This is the result of trace headers changing between retries and failing the signing verification processes. We've submitted a Pull Request to the AWS JS SDK and will be updating accordingly.","To prevent this issue from arising, add the code snippet below to your code."]}],[{"l":"Vercel","p":["Vercel is a cloud platform for hosting and deploying web applications and websites. It is designed to make the process of deploying, scaling, and managing web apps as simple and efficient as possible. Vercel offers a variety of features and tools for web developers."]},{"l":"Baselime Integration","p":["Baselime provides advanced observability capabilities for applications running on Vercel.","Install the integration for free on the Vercel marketplace and start observing your Vercel apps in minutes."]},{"l":"How it works","p":["When you install the Baselime integration on the Vercel Marketplace, Baselime automatically creates a log drain on your Vercel account to start streaming all your logs in real-time.","Once Baselime receives your data, we automatically discover all your Vercel apps and ingests all your logs into three datasets:","vercel-build: logs from your Vercel build steps","vercel-edge: logs from Vercel Edge functions","vercel-functions: logs from Vercel functions such as API routes","vercel-static: logs from requests to static assets on Vercel such as HTML and CSS files","The logs are separated in multiple datasets to give you a complete view of your Vercel applications."]},{"l":"Using the Vercel integration","p":["All the logs from your Vercel apps are streamed to Baselime. You can search, query or tail your logs from the console and the CLI. You can create alerts from derived metrics from your logs. You can use our dashboard templates to create dashboards based on your Vercel logs, and modify them at will.","Vercel Logs in Baselime"]}],[{"l":"Cloudflare Workers","p":["Cloudflare Workers are an edge platform that enabled developers to build serverless applications and deploy instantly across the globe for exceptional performance, reliability, and scale.","Baselime offers advanced monitoring capabilities for applications running on Cloudflare Workers. This guide will help you connect your Cloudflare account to Baselime, enabling you to monitor your Cloudflare Workers effectively."]},{"l":"Using Logpush","p":["Logpush is available only to accounts subscribed to the Cloudflare Workers Paid Plan","Baselime connects to your Cloudflare account and enables Logpush to stream your Worker Trace Event Logs to Baselime. You can connect your account in 3 steps:"]},{"l":"1. Create an API Token","p":["To get started, you need to create an API token for your Cloudflare account. This token will enable Baselime to access create the Logpush and add metadata to your events once they are ingested into Baselime.","Create a user API token with the following permissions from the Cloudflare Dashboard:","Logs - Edit: This permission is required to set up logpush configurations to collect logs from Cloudflare.","Account Settings - Read: This permission is needed to list the accounts and add them to Baselime automatically.","Select all the Cloudflare accounts you want to observe in Baselime. Cloudflare Token Creation","Learn more about API tokens in the Cloudflare Docs"]},{"l":"2. Connect Your Cloudflare Account to Baselime","p":["Use the API Token you created in the previous step to connect your Cloudflare account to Baselime in the Baselime console.","Step 1: Create a new environment","Add Environment","Step 2: Add the API token you created in the previous step and connect your Cloudflare account.","Add your API Token"]},{"l":"3. Enable Logpush on Your Cloudflare Workers","p":["To complete the setup, it's necessary to enable Logpush on your Cloudflare workers.","Add logpush = true to the top level section of your Workers wrangler.toml file","Learn more about enabling Logpush on your Cloudflare workers."]},{"l":"4. Using the Cloudflare Workers Logpush integration","p":["Once you've connected your Cloudflare account to Baselime, all your Workers Trace Events will be available in Baselime. You can search, query or tail your logs from the console and the CLI. You can create alerts from derived metrics from your logs. You can use our dashboard templates to create dashboards based on your Cloudflare events, and modify them at will."]}],[{"l":"AWS","p":["When you connect your AWS account to Baselime, logs, metrics, traces and events from your AWS services are sent to Baselime automatically."]},{"l":"AWS Data Sources","p":["AWS AWS AWS AWS AWS AWS AWS"]}],[{"l":"AWS Lambda Logs","p":["Once you connect your AWS account to Baselime, it automatically creates CloudWatch Logs subscription filters to ingest logs from your AWS Lambda functions.","Baselime automatically captures logs for newly created AWS Lambda functions, and enables you to query and visualise logs across multiple log groups and log streams.","It is possible to send logs from AWS Lambda functions to Baselime directly using the Baselime AWS Lambda Extension, and bypass Amazon CloudWatch for cost considerations."]},{"l":"How it works","p":["Once Baselime is connected to an AWS Account, it automatically creates Logs subscription filters for all the AWS Lambda functions in the account. Log subscription filters enable Baselime to asynchronously ingest logs from the AWS Lambda functions through Amazon CloudWatch, without any impact on the performance of the AWS Lambda functions.","Sending Lambda Logs to Baselime","Moreover, Baselime automatically creates new subscription filters for newly deployed AWS Lambda functions. Baselime listens to new AWS Lambda events in Amazon CloudTrail and creates subscription filters for newly created AWS Lambda functions.","AWS Lambda Logs in Baselime"]},{"l":"Logs using the AWS Lambda Extension","p":["This section is relevant only if you want to disable logs from Amazon CloudWatch and send logs from your AWS Lambda functions directly to Baselime.","For use-cases where you want to by-pass Amazon CloudWatch and send logs directly to Baselime from your AWS Lambda functions, use the Baselime AWS Lambda Extension.","The Baselime AWS Lambda Extension listens to invocation events and collects telemetry data, such as logs and runtime metrics."]},{"l":"Instrumenting","p":["To instrument your AWS Lambda Functions with the Baselime AWS Lambda Extension, add the extension as an AWS Lambda Layer.","It is required to add your public Baselime API key to your functions as an environment variable.","Where the BASELIME_KEY is your public Baselime API Key and the BASELIME_LAMBDA_LAYER_ARN is the ARN of the Baselime AWS Lambda extension in your region.","The Baselime AWS Lambda Extension is language agnostic and is compressed as a single binary, to minimise its impact cold-starts and performance.","Using the Baselime Lambda Extension","All the logs and metrics from your AWS Lambda function is collected asynchronously from your invocation, and sent to the Baselime backend in a separate process from your invocation, with no impact on the latency your users experience."]},{"l":"Configuration","p":["When using the Baselime AWS Lambda Extension, it is not necessary to use Amazon CloudWatch for AWS Lambda logs. To disable Amazon Cloudwatch logs, add an explicit deny IAM policy that prevents the creation of log streams and log events for your function."]},{"l":"Logging best practices","p":["In order to get the most out of Baselime, we recommend adding two log messages to all your AWS Lambda functions:","the event which triggered your Lambda function","the response your Lambda function returns","These can be added as follows:","To facilitate this in Node.js runtimes, we maintain a custom logger well suited for AWS Lambda.","It's a 2.5kb JavaScript file with 0 dependencies, and does not have any significant impact on performance or cold-starts.","It also provides an interface to be used as a middy middleware."]},{"l":"Logging format","p":["We recommend using structured logging across your application, preferably in JSON format. Feel free to use your favourite logging library; we recommend:","Baselime Lambda Logger for Node.js","Lambda Power Tools","It is particularly important to format errors and exception correctly to appropriately log stack traces.","or with the Baselime Lambda Logger for Node.js:"]},{"l":"Discovered Keys","p":["Baselime automatically discovers key - value pairs from your AWS Lambda logs. This enables you to run complex queries and setup alerts on data that otherwise would be difficult to work with from the AWS Lambda service. For instance, from the discovered keys from the Lambda logs, it's possible to set alerts on the maximum memory used by lambda functions during execution, compared to the amount of memory they are assigned at deployment time."]},{"l":"Lambda Discovered Keys","p":["The Lambda service automatically writes logs at the start and end of every function invocation. These logs are parsed as events in Baselime, and keys are automatically discovered from those messages."]},{"l":"START Log Message","p":["The following keys are discovered from the START message:","@type: is always START","@requestId: the request ID of the Lambda invocation","@version: the invoked version of the Lambda function"]},{"l":"END Log Message","p":["The following keys are discovered from the END message:","@type: is always END","@requestId: the request ID of the Lambda invocation"]},{"l":"REPORT Log Message","p":["The following keys are discovered from the REPORT message:","@type: is always REPORT","@requestId: the request ID of the Lambda invocation","@duration: the duration in milliseconds","@billedDuration: the billed duration in milliseconds","@memorySize: the total memory available to the invocation, in MB","@maxMemoryUsed: the max memory used, in MB","@initDuration: the duration of the lambda initialisation in milliseconds (cold starts)","If the Lambda function is instrumented with XRAY, additional keys are discovered:","@xRAYTraceId: the XRAY trace ID","@segmentId: the XRAY segment ID","@sampled: always true"]},{"l":"Timeout Invocations","p":["If your async Lambda invocation times out, Additional keys are automatically discovered:","@timedOut: always true","@timeout: the duration after which the invocation timed-out in seconds","@message: always Task timed out after {@timeout} seconds","@timestamp: the timestamp at the moment the invocation timed out."]},{"i":"consolelog-log-message","l":"console.log Log Message","p":["For Node.js environments, AWS Lambda uses a modified version of console.log(and other console logging functions) to write to stdout and stderr. These add fields to the log message which are parsed as follows:","@timestamp: the timestamp at the moment the log message was written","@requestId: the request ID of the Lambda invocation","LogLevel: the log level ( INFO, DEBUG, WARN, ERROR)","@message: the message.","If the message in @message is a valid JSON object, Baselime will parse it, otherwise it will be considered a string."]},{"l":"Troubleshooting","p":["If you're having trouble sending data from your AWS Lambda logs to Baselime, here are a few things to check:","Verify that your AWS account is correctly connected to Baselime and you receive data in other datasets such as CloudWatch Metrics or CloudTrail Events","Check that your Lambda functions are not already using the maximum number of subscription filters allowed per log group. AWS limits each log group to 2 subscription filters at most. If you're already at the limit, you can remove subscription filters with the cloudwatch-subscription-filters-remover to delete the ones you don't need anymore.","Make sure that your AWS Lambda functions are being invoked and you can view the logs in the CloudWatch section of the AWS Console"]}],[{"l":"Amazon ECS Container Logs","p":["This page describes how to collect application container logs from Amazon ECS clusters launched with AWS ECS using AWS FireLens. This method can also be used to collect ECS clusters with EC2 containers."]},{"l":"How it works","p":["FireLens is an Amazon ECS native log router that enables you to send logs from your containerized applications to different destinations, including Baselime. By adding the FireLens sidecar to your task definitions, you can configure and route your container logs to different destinations without modifying your application code.","Sending ECS Logs to Baselime","Each of your ECS tasks can take a sidecar container running the FireLens log driver that will forward all the logs from the containers to Baselime."]},{"l":"Configuring your ECS Tasks"},{"i":"step-1-obtaining-your-baselime-api-key","l":"Step 1: Obtaining your Baselime API Key","p":["You can get your public Baselime API key in the Baselime console from the Baselime CLI.","In the following instructions we will use BASELIME_API_KEY to refer to your Baselime API key."]},{"i":"step-2-adding-the-firelens-sidecar-to-your-task-definitions","l":"Step 2: Adding the FireLens sidecar to your task definitions","p":["Adding the FireLens sidecar to your task definitions is a straightforward process that can be accomplished using various Infrastructure as Code solutions or manually in the console.","Add the Baselime ECS endpoint to your FireLens configuration:","Endpoint ecs-logs-ingest.baselime.io","Header: x-api-key BASELIME_API_KEY","Amazom ECS Logs in Baselime"]},{"l":"Troubleshooting","p":["If you're having trouble sending data from your AWS ECS logs to Baselime, here are a few things to check:","Verify that you're using the correct API key and host in the FireLens configuration","Make sure that your containers are receiving traffic and are writing logs to either stdout or stderr","Check the logs of the FireLens container to look for any anomaly"]}],[{"l":"AWS X-Ray Traces","p":["AWS X-Ray enables developers to generate and collect traces across their distributed services. In order to gain visibility into their applications, developers can use AWS X-Ray to trace requests as they travel through their application, and collect data about the performance of their application.","Baselime enables you to ingest this tracing data and make it available for analysis and troubleshooting.","AWS X-Ray trace diagram in Baselime AWS X-Ray trace waterfall in Baselime"]},{"l":"How it works","p":["Once Baselime is connected to an AWS Account, it will periodically poll your AWS account for new traces and automatically ingest them into your Baselime dataset.","Sending X-Ray Traces to Baselime"]},{"l":"Troubleshooting","p":["If you're having trouble sending data from AWS X-Ray to Baselime, here are a few things to check:","Verify that your AWS account is correctly connected to Baselime and you receive data in other datasets such as CloudWatch Metrics or CloudTrail Events","Check that the Baselime IAM user has the appropriate permissions to access AWS X-Ray","Make sure that your applications emit X-Ray traces and you can view the traces in the X-Ray section of the AWS Console","Baselime will ingest traces emmitted by the AWS X-ray service. To capture HTTP calls or AWS Service calls, you must manually instrument your code with the AWS X-Ray SDK. Read more in the AWS X-Ray docs."]}],[{"l":"Amazon API Gateway Logs","p":["Once you connect your AWS account to Baselime, Baselime automatically create CloudWatch Logs subscription filters to automatically ingest logs from your Amazon API Gateways."]},{"l":"Setup","p":["Baselime can ingest logs only for Amazon API Gateways where access logs are appropriately configured.","We recommend this configuration for Amazon API Gateway logs:","It is possible to enable Amazon API Gateway access logs from your favourite Infrastructure as Code tool, using the CLI or in the AWS console. Below is an example of how to enable Amazon API Gateway logs using the serverless framework."]},{"l":"How it works","p":["Once Baselime is connected to your AWS Account, it automatically creates Logs subscription filters for all the Amazon API Gateways in the account.","Sending API Gateway Logs to Baselime","Moreover, Baselime automatically creates new subscription filters for newly deployed Amazon API Gateways. Baselime listens to new API Gateway events in Amazon CloudTrail and creates subscription filters for newly created Amazon API Gateways."]}],[{"l":"AWS App Runner Logs","p":["Once you connect your AWS account to Baselime, Baselime automatically create CloudWatch Logs subscription filters to automatically ingest logs from your AWS App Runner logs."]},{"l":"How it works","p":["Once Baselime is connected to your AWS Account, it automatically creates Logs subscription filters for all the AWS App Runner services in the account. AWS App Runner automatically creates two log groups for each service:","/aws/apprunner/service-name/unique-id/application: the logs from the container running","/aws/apprunner/service-name/unique-id/service: the internal logs of the AWS App Runner service, typically deployment logs","Baselime create subscription filters for the log groups ending in /application: the logs from the container.","Sending AWS App Runner logs to Baselime","Moreover, Baselime automatically creates new subscription filters for newly deployed AWS App Runner services. Baselime listens to new App Runner events in Amazon CloudTrail and creates subscription filters for newly created AWS App Runner services."]},{"l":"Troubleshooting","p":["If you're having trouble sending data from your AWS App Runner logs to Baselime, here are a few things to check:","Verify that your AWS account is correctly connected to Baselime and you receive data in other datasets such as CloudWatch Metrics or CloudTrail Events","Check that your App Runner services functions are not already using the maximum number of subscription filters allowed per log group. AWS limits each log group to 2 subscription filters at most. If you're already at the limit, you can remove subscription filters with the cloudwatch-subscription-filters-remover to delete the ones you don't need anymore.","Make sure that your AWS App Runner services are being live and you can view the logs in the CloudWatch section of the AWS Console."]}],[{"l":"Amazon CloudTrail","p":["Baselime automatically ingests Amazon CloudTrail events when you connect your AWS account. Baselime will automatically create a new Amazon CloudTrail trail and an Amazon S3 bucket, and configure both to send data to your Baselime account. No additional setup is required.","Once connected, Amazon CloudTrail events will be sent to Baselime and become available for querying."]},{"i":"why-amazon-cloudtrail-","l":"Why Amazon CloudTrail ?","p":["Amazon CloudTrail is a service provided by AWS that records API activity in your AWS account. This data can be used to track changes to your resources, troubleshoot issues, and improve security.","By sending Amazon CloudTrail events to Baselime, you can use our query and visualization tools to analyze and understand your API activity. You can also set up alerts to be notified of specific API activity or trends.","With Amazon CloudTrail events in Baselime, you can gain a deeper understanding of your AWS API activity and use that knowledge to improve the security and reliability of your applications."]},{"l":"How it works","p":["Amazon CloudTrail periodically writes trail data in a pre-configured Amazon S3 bucket in your AWS account. Once the data is written, an Amazon SNS topic is triggered.","Baselime configures this Amazon SNS to invoke an AWS Lambda function. This function reads the data from the bucket and sends it to the Baselime backend.","Sending CloudTrail data to Baselime"]},{"l":"Amazon CloudTrail management events","p":["Amazon CloudTrail events fall into multiple categories, and Baselime automatically ingests CloudTrail management events. Please refer to the complete CloudTrail docs for further details on the CloudTrail concepts."]}],[{"l":"Amazon CloudWatch Metrics","p":["Baselime automatically collects Amazon CloudWatch Metrics from your AWS account. Once you connect your AWS account to Baselime, the necessary resources including a CloudWatch Metrics Stream and a Kinesis Firehose will be automatically created and configured. No additional setup or configuration is required."]},{"i":"why-amazon-cloudwatch-metrics-","l":"Why Amazon CloudWatch Metrics ?","p":["Amazon CloudWatch is a monitoring service provided by AWS that enables you to collect and track metrics for your AWS resources and applications. Metrics are important as they provide insight into the performance and behavior of your applications and the underlying infrastructure.","Amazon CloudWatch Metrics can help you identify issues such as high error rates and latencies, which can help improve the overall reliability and scalability of your applications.","Amazon CloudWatch Metrics cover all aspects of your architecture automatically, from DynamoDB tables to S3 buckets and SQS Queues."]},{"l":"How it works","p":["Once Baselime is connected to an AWS Account, it automatically created the telemetry pipeline for ingesting Amazon CloudWatch metrics into Baselime. The pipeline comprises a CloudWatch Metrics Stream, a Kinesis Firehose and all IAM roles and permissions associated.","This pipeline automatically and continuously sends metrics from your AWS account to Baselime.","Sending Amazon CloudWatch Metrics to Baselime","Amazon CloudWatch Metrics Stream might incur a minimal cost on your AWS account. AWS charges $0.003 per 1,000 metric updates. Refer to the AWS docs for more details."]},{"l":"Custom Amazon CloudWatch Metrics","p":["Baselime automatically ingests all metrics published to Amazon CloudWatch. This includes both standard Amazon CloudWatch metrics and any custom metrics that you may have created.","There is no need to manually configure or set up anything to start ingesting custom Amazon CloudWatch metrics. Once your AWS account is connected, all metrics will be available for querying in Baselime."]},{"l":"Querying Amazon CloudWatch Metrics","p":["Once your AWS account is connected to Baselime, you can use any of the our clients to visualize and query your Amazon CloudWatch Metrics. You'll have access to all the metrics available in your AWS account, and you can filter and aggregate the data in near real-time."]},{"l":"Troubleshooting","p":["If you're having trouble sending metrics from Amazon CloudWatch to Baselime, here are a few things to check:","Verify that your AWS account is correctly connected to Baselime and you receive data in other datasets such as AWS Lambda Logs or CloudTrail Events","Check that the Kinesis Firehose created in your AWS account as part of the Baselime connection has the appropriate API key to connect with the Baselime backend. If the API key is missing, please contact us."]}],[{"l":"Events API","p":["Baselime provides an Events API which enables you to send data to Baselime by making a POST request to the API endpoint. It enables your to send data directly from your applications or services to Baselime, rather than using a logging or monitoring service as an intermediary."]},{"l":"Request Format","p":["Each request ingests a batch of events into Baselime. Events are part of the request body. Baselime supports Content-Type application/json.","The request body must be an array of JSON objects. Any element of the array that cannot be parsed as valid JSON will be rejected.","Requests must be made to the /dataset/service/namespace route:","dataset is the name of the dataset that the events should be ingested into.","service is the service that the events belong to.","namespace is the namespace within the dataset that the events should be ingested into."]},{"l":"Authentication","p":["Add a public Baselime API key in the x-api-key header to all requests made to the Events API. You can get your API key from the Baselime console."]},{"l":"Validation","p":["The Events API validates the every request and returns a 400 Bad Request status code if any of the events fail validation. If some events pass validation and others fail, Baselime will ingest the events that pass validation. If you encounter a 400 Bad Request error when submitting events to the Events API, the events that failed validation will be listed in the body of the request under the invalid key."]},{"l":"Requirements","p":["Baselime accepts up to 6MB of uncompressed data per request","Each event must be a properly formatted JSON","Each event must be smaller than 256kb of uncompressed JSON"]},{"l":"API Response codes","p":["Baselime returns a 202 response for all valid requests to the Events API, and a range on of non- 200 responses for errors.","We welcome feedback on API responses and error messages. Reach out to us in our Slack community with any request or suggestion you may have."]},{"l":"Successful responses","p":["Status Code","Body","Meaning","202","{message: Request Accepted}","All the events were successfully queued for ingestion"]},{"l":"Failure responses","p":["Status Code","Body","Meaning","405","{message: Method Not Allowed}","The HTTP method is not allowed","401","{message: Unauthorised}","Missing or invalid API Key","400","{message: Bad Request}","- Missing or invalid path parameters ( v1, dataset, service or namespace) - Unable to parse the request body as valid JSON- Empty request body - At least one of the events exceed the 256kb size limit - At least one of the events could not be parsed as valid JSON","500","{message: Internal Error}","An unexpected error occurred"]}],[{"l":"Docker Logs","p":["Docker allows you to configure a logging driver for each container. By using Fluentd as your logging driver you'll be able to stream your logs to Baselime over HTTPS."]},{"i":"what-is-fluentd","l":"What is Fluentd?","p":["Fluentd is an open source data collector for unified logging layer that is widely used by companies such as AWS, Google, Microsoft, and more."]},{"i":"how-to-use-fluentd-with-baselime","l":"How to use Fluentd with Baselime?","p":["First obtain the API key from the Baselime console.","Next, create the following configuration file for Fluentd.","Make sure to replace YOUR_API_KEY with the API key you obtained from the Baselime console.","Now you need to start the Fluentd container and mount the configuration file you created.","Next, you need to configure your Docker container to use Fluentd as the logging driver.","Pay attention to the labels options. It is used to extract the service and namespace fields."]},{"l":"Using Docker Compose","p":["If manage your containers with Docker Compose, you can use the following configuration YAML."]},{"l":"Best practices","p":["We expect the log messages to be in JSON format. For example:","or"]},{"l":"Docker Labels","p":["Make sure to set these labels on your Docker containers:","io.baselime.service- used to extract service name used in Baselime console.","io.baselime.namespace- used to extract the namespace used in Baselime console."]},{"l":"How it works","p":["Sending Telemetry data to Baselime","By defining logging driver as Fluentd and providing Docker with the Fluentd address, the Docker will send your logs over TCP to Fluentd. In the above example, we've provided as localhost:24224 as the Fluentd address. This value needs to be adjusted accordingly to your environment and network configuration.","Using provided Fluentd configuration, Fluentd will match the incoming logs and send them to Baselime over HTTPS. The API Key is used to authenticate the request and route the logs to your workspace and environment.","You can find example implementation in our GitHub repository"]}],[{"l":"Kubernetes Logs","p":["If you use Docker as your container runtime, you can stream your container logs to Baselime by using Fluentd as your logging driver"]},{"i":"what-is-fluentd","l":"What is Fluentd?","p":["Fluentd is an open source data collector for unified logging layer that is widely used by companies such as AWS, Google, Microsoft, and more."]},{"i":"how-to-configure-fluentd-to-stream-kubernetes-logs-to-baselime","l":"How to configure Fluentd to stream Kubernetes logs to Baselime?","p":["The setup is very similar to the Docker setup","First obtain the API key from the Baselime console.","Next, create a ConfigMap that will contain the Fluentd configuration.","Make sure to replace YOUR_API_KEY with the API key you obtained from the Baselime console.","Next, we need to create a DaemonSet that will run Fluentd on each node in your cluster."]},{"l":"Best practices","p":["We expect the log messages to be in JSON format. For example:"]},{"l":"Required fields","p":["message- The log message","timestamp- The timestamp of the log message in seconds since epoch (Unix time) or ISO 8601 format","service- The name of the service that generated the log message","namespace- The namespace of the service that generated the log message"]},{"l":"How it works","p":["Sending Telemetry data to Baselime","DaemonSet provided above creates an instance of FluentD pod on each node in your cluster. The FluentD pod reads the logs from the /var/log/containers/*.log and /var/log/pods/*.log directories and sends them to Baselime over HTTPS.","You can find example implementation in our GitHub repository"]}],[{"l":"Rehydrating telemetry data from Amazon S3","p":["This page describes how you can rehydrate your telemetry data from Amazon S3 into Baselime.","Once received, all telemetry data from your AWS Accounts is securely stored in hot storage for querying and in cold storage within your own AWS environment, in an Amazon S3 bucket in your AWS account. This ensures that you have complete long-term control over your data and its storage location.","Sending Telemetry data to Baselime","The retention period of your telemetry data on Baselime is independent of the retention periods in AWS. You can safely reduce the retention period of your CloudWatch log groups."]},{"l":"How it works","p":["When your data is streamed to Baselime, through different sources described in the Sending Data to Baselime section, it is also streamed to a Kinesis Firehose created in your AWS account. The Data Firehose stores the telemetry data in a S3 bucket in your AWS account.","This gives you full ownership of your data and enables you to use it outside the Baselime; for example to feed it into a data lake. It is also possible to rehydrate the data from the S3 bucket into Baselime once the data is past its expiration period on Baselime.","Data flow","We set the default TTL for objects stored in the bucket to 180 days to prevent extremely long storage of telemetry data you might not need; Feel free to adjust it to your needs."]},{"l":"How to use it","p":["First, you'll need to have Baselime CLI installed. You can find the installation instructions here.","Once you have it installed, you can use the following command to rehydrate your data:","Start date should be formatted in RFC3339 format, and hours to recover should be a number. The process will recover all the data from the start date, for the number of consecutive hours from that date."]}],[{"l":"Vector Logs","p":["Vector is a high-performance, open-source, observability data router. It can be configured to stream your logs to Baselime over HTTPS."]},{"i":"how-to-use-vector-with-baselime","l":"How to use Vector with Baselime?","p":["First obtain the API key from the Baselime console.","Next, create Vector configuration file vector.yaml with the following content:","Make sure to use name of the Vector container under exclude_containers option. This will prevent Vector from sending its own logs to Baselime.","Replace YOUR_API_KEY with the API key you obtained from the Baselime console.","Finally, start Vector container and mount the configuration file you created."]},{"l":"Docker Labels","p":["Make sure to set these labels on your Docker containers:","io.baselime.service- used to extract service name used in Baselime console.","io.baselime.namespace- used to extract the namespace used in Baselime console."]},{"l":"How it works"}],[{"l":"Data Validation","p":["Baselime has a size limit for events of 256kb. This size limit helps ensure that the ingestion process is efficient and that the data stored in Baselime is manageable and fast to query. If an event exceeds this 256kb size limit, it will not be ingested into Baselime."]},{"l":"Sending Semi-Structured Logs to Baselime","p":["Semi-structured logs are logs that are not in the strict JSON format, but still contain structured data that can be extracted. These logs contain a mixture of structured and unstructured data, making them difficult to parse and analyze. Baselime has built-in mechanisms to parse and extract relevant data from semi-structured logs.","Baselime will automatically detect log events that contain JSON data, but are prepended or appended by a generic string.","The generic string will be wrapped in a message attribute, and the JSON data will be wrapped in a data attribute. This enables you to extract and analyze relevant data from semi-structured logs."]},{"l":"Examples","p":["Here are examples of automatic semi-structured logs detection."]}],[{"l":"Troubleshooting in Baselime","p":["Baselime enables you to troubleshoot your systems and find issues faster. You can search, slice and dice your data against any dimension to get answers to your questions."]},{"l":"Search","p":["Once you've created an environment in Baselime and sent data (logs, metrics, traces or wide events), you can search for any string or regular expression in your data.","Click on your environment","Click on one of the discovered services (or the default service)","Enter your search expression","Baselime will surface all the requests where the search expression is found. This search is performed on logs, spans, span events and wide events.","Search in Baselime","Expand each request to view the logs and the trace of the specific request."]},{"l":"Filter","p":["From any screen on Baselime with telemetry data, you can filter the data by any of the fields persent in the data.","Baselime supports high cardinality and high dimensionality. This means you can send data with as many nested fields as you want, and those fields can have as many possible values as you want. For example, in your logs or traces, you can send a requestId to Baselime, which can have millions of unique values; and you will be able to filter by any of these values.","Filter in Baselime"]},{"l":"View requests and traces","p":["Once you've searched an/or applied filters to your telemetry data, you can drill down into a single request or trace, view all the logs, spans and span events related to the request.","Request logs in Baselime Trace map in Baselime Trace timeline in Baselime"]},{"l":"Compute aggregates","p":["Add a filter $baselime.error EXISTS","Add a group by @message or @message.message","Add a order by","add a search expression","Add a visualisation COUNT","add more visualisations, filters, and group bys","Baselime has an internal tab system. Start a new tab by clicking on the + at the top of the screen, select Start new query and Start from scratch.","Baselime query builder","Click Run query","Sometimes you want to troubleshoot an issue that impacts more than one user. For example, you might want to count the number of requests that returned an error status code and group them by route, or you might want to compute the latency of your requests.","The Baselime query builder is the most powerful way to explore your data in Baselime. It gives your the tools to keep drilling down and surface insights from your telemetry data.","This is where the Baselime query builder shines.","view the raw data (the list of events) that match the filters","view the requests and traces associated with these events","You'll see a count of all the events where there was an error, grouped by the error message. You can zoom:","zoom in on the chart"]}],[{"l":"Real-Time Error Tracking in Baselime","p":["Baselime automatically tracks all errors occuring in your applications and notifies you with those that need your attention in real-time."]},{"l":"Errors","p":["The Errors page displays errors in your applications, across your services. You can filter errors by service or search using case-sensitive search.","When you connect your cloud account to Baselime, your applications send logs, metrics, traces and wide events to Baselime. On each event, Baselime determines if it's an error. This is typically determined by:","The log level: anything above error or critical log level","The status of the span: every span with an error (from both OpenTelemetry and AWS X-Ray)","If the event has a root level property level set to error or critical.","Baselime then computes the fingerpring of the error. The fingerprit is based on multiple variables, such as the service name, the environment, the route, the error message or cause, the serverless function name or the container id. Errors are uniquely represented and grouped by their fingerprint. If a similar error with the same fingerpring occurs, you will not get notified, the occurences counter will increase instead.","The occurences counter is refreshed after 30 days since the first occurence of the error, and you and your team will be notified again."]},{"l":"Error status","p":["Errors can have a status in Baselime:","Active","Ignored","Resolved","You can change the status of any error from the Baselime console. The status reflects the behaviour of the error fingerprint when the same error is occurs again in your architecture."]},{"l":"Active errors","p":["This is the default status of all errors when they are detected. When an error in Active state occurs, you will get notified only the first time it happens. You will not not get notified again until the fingerprint expires 30 days after the first occurence of the error. As such, if the error is not resolved within 30 days and it occurs again, you will get notified."]},{"l":"Ignored errors","p":["When an error in Ignored state occurs, you will not get ever. This is useful for expected errors, where they occur in your applications, but no action is required."]},{"l":"Resolved errors","p":["When an error is marked as Resolved, you will get notified the first time it happens again, and it will be automatically marked as Active. This is helpful for when you have resolved an error in your applications, but it happens again for a set of edge-cases. You will know about it as soon as it happens again."]},{"l":"Deleting Errors","p":["You can delete errors. When you delete an error, all its history is lost, and this action is irreversible. If the same error occurs again in the future, we will create a new Error for it and notify you as per your notification settings."]},{"l":"Assigning Errors","p":["You can assign an error to any of your member of your team to facilitate error triage."]},{"l":"Error details","p":["The error details page gives you an overview of the error and enables you to dig deeper into the data and understand why the error occured.","It displays the first and last time the error was seen in your telemetry datam the number of occurences in the past 30 days, the cloud account the error originates from, and the dataset. From this screen it is also possible to directly change the status of an error or assign it to a member of your team.","For each error, the errors details screen also displays:","A sample request","A sample trace","A sample error event","The 30-day History of occurences","From this screen you can click on the Investigate button to hop into the query builder to dig deeper in the issues."]}],[{"l":"Service Home","p":["Every service in Baselime has a service home. The service home is where you get both a high-level overview of your service as well as the ability to drill down and investigate issues quickly."]},{"l":"Requests","p":["The requests view displays a summary of your requests and the list of the requests within the selected timeframe in chronological order."]},{"l":"Summary","p":["The summary includes three charts:","Number of events: the total number of events your service emitted","Errors: the total number of errors in your telemetry data","Request latencies the 90th percentile latencies of requests and traces","You can drill down on any of these charts by clicking on the chart. It opens the Baselime query builder where you can slice and dice your data further."]},{"l":"List of requests","p":["Below the summary charts, there is a search bar, a filter button and the list of requests.","You can search for any string or regular expression using the search bar. Baselime will search through all the events (logs, spans, span events and wide events) from your service and display the requests where at least one event matches the search criteria.","You can filter by any high-dimensionality field in your data using the filter button. Baselime fill filter through all the events (logs, spans, span events and wide events) from your service and display the requests where at least one event matches the applied filters.","If you add simultaneously a search criteria and filters, Baselime will find events that matches all searches and filters and displat the corresponding requests.","You can expand each request and view the logs and the trace of the request. Also, to facilitace filtering, it's possible to filter directly from the logs or the trace of a request. Use the option menu at the end of each line in the events JSON.","The menu inside the JSON event is available across Baselime, wherever an event is displayed. This enables you to quickly go from an event to investigating further, without loosing the context of the event."]},{"l":"Events","p":["The events view displays all the events captured your service during the selected timeframe. The events comprise all logs, spans, span events, wide-events and metrics sent to Baselime.","You can search for events and filter events from this view. You can zoom in on the bar chart of the event volume."]},{"l":"Traces","p":["The traces view displays the traces captured from your service within the selected timeframe. It includes a trace scatter plot, where the y-axis is the duration of the traces and the x-axis is the timestamp. In addition to the scatter plot, the trace view displays a list of traces from your service in chronological order.","You can search and filter traces using the search bar and the filter button.","The scatter plot is color-coded:","Red: traces with at least one span with an error","Green: succesful traces","Blue: Traces where there is a cold-start (for serverless functions)","You can click on any of the dots in the scatter plot to display the trace.","You can also click on any of the traces in the list to display the complete trace.","Once you're viewing a trace, you can click on any of the spans to view the the span the logs of the traces, the span events, and the span details."]}],[{"l":"Baselime AI","p":["Baselime AI provides explanations for any chart, log, event, metric or trace on Baselime. It enables you to identify patterns and anomalies in your systems, providing deeper insights into your system performance and behavior."]},{"l":"Getting Started","p":["Youll need a Baselime account to start using Baselime AI. If you don't have one already, you can quickly sign up for a free trial on our website.","Once you have an account, follow these steps to use Baselime AI:","Navigate to the Baselime dashboard and select the chart, log, event, metric, or trace you want to analyze.","Click on the \"Ask AI\" button located next to the chart.","Wait for Baselime AI to process your query and provide a response.","Baselime AI explaining an error"]},{"l":"How it Works","p":["Baselime AI is built using OpenAI's Large Language Models. When you ask Baselime AI a question, it analyzes the data in the selected chart or event, and uses machine learning algorithms to identify any anomalies or patterns.","Once Baselime AI has identified potential issues, it generates a response that explains the root cause of the problem, as well as any recommended actions to fix it. The response is presented in natural language, enabling developers of all skill levels to understand."]},{"l":"Benefits","p":["Baselime AI offers a range of benefits, including:","Streamlined debugging: Baselime AI enables you to quickly identify and fix issues, reducing the time and effort required for debugging.","Improved system observability: With Baselime AI, you can gain deeper insights into your system performance and behavior, enabling you to optimize your systems and improve overall system observability.","Accessible to all skill levels: Baselime AI's natural language explanations enable developers at all skill levels to understand and interpret results."]},{"l":"Privacy","p":["Baselime is committed to protecting the privacy of our users' data. We understand the importance of keeping data secure and confidential, and we take appropriate measures to safeguard it.","When you use Baselime AI, your data is processed in accordance with our privacy policy. Before any data is sent to OpenAI, it is completely anonymized to protect the privacy of our users. This is done through a process called obfuscation, which replaces identifiable information with obfuscated tokens.","Once data has been anonymized, it is sent to OpenAI for processing. OpenAI is a trusted provider of AI services, and we have taken steps to ensure that your data is processed in accordance with our privacy policy and our high standards for data security.","Simplified Baselime AI architecture diagram","The diagram above shows a simplified overview of the data flow and privacy measures taken in Baselime AI. When you request an explanation for a chart, log, event, metric, or trace, the data is first processed and analyzed by Baselime AI. This analysis is done locally within our system to ensure that sensitive data is not transmitted. Only after data is anonymized through obfuscation is it sent to OpenAI for processing. OpenAI processes the data and returns an explanation to our system, which is then delivered to you.","We take data privacy seriously and are committed to ensuring that your data is protected at all times. If you have any questions or concerns about our privacy policy or data security, please don't hesitate to contact us."]}],[{"l":"Automatic Service Discovery","p":["Baselime automatically discovers services in your cloud accounts and organises your observability data following services and teams boundaries. This ebales you to quickly sift through the vast amounts of data your applications produce."]},{"l":"Discovering Services","p":["Baselime automatically discovers all cloud resources in your cloud accounts. Each resource is linked to a service. The service is typically based on the deployment framework that you use.","The service name is the name of the CloudFormation template the AWS CDK generates during cdk synth","The name of the service is the name of the SST app","The name of the service is the name of the Serverless Framework App","The name of the service is the name of the CloudFormation template generated when deploying the AWS SAM application","The name of the service is the name of the CloudFormation template","When ingesting data from your architecture, Baselime correlates the incoming data with the service name of the cloud resource the data originates from."]},{"l":"Overriding the service discovery on AWS","p":["To force the resources from a CloudFormation stack to belong to a service with a different name, set the value of the tag baselime:service to the desired service name on the CloudFormation template. All resources deployed with the CloudFormation template will be correlated with the desired service name."]}],[{"l":"Inventory","p":["The inventory displays a set of resources available in your cloud account. The available resources currently are:","AWS Lambda Functions","Amazon ECS Services","Amazon DynamoDB Tables","We're continiously adding more cloud services to the inventory view.","From the inventory view, you can navigate to any individual cloud resource."]}],[{"l":"Queries","p":["Queries are the building blocks of all interactions with your telemetry data on Baselime. When you view a request or a trace, it's the result of a query.","You can run queries both in the Baselime console and using the Baselime CLI."]},{"l":"Queries in the Console","p":["From anywhere in the Baselime console you can start a new query by clicking on the \"New query\" button.","You can use the query builder to construct queries to explore your data, investigate issues and resolve performace bottlenecks. The query builder is aware of your observability data and will recommend values such that you always query within the context of your data.","Sending AWS App Runner logs to Baselime"]},{"l":"Queries in the CLI","p":["You can also run queries using the Baselime CLI. To do so, use the baselime query command.","Use the baselime query without any flags to enter interactive mode where you can specify all the arguments of your query interactively.","You can also run saved queries using the CLI, either in interactive mode or by passing the arguments as flags","You can also save your query results to a file. Use the --format to print the results of the query in JSON, and pipe them to a file.","For more advanced usage of the baselime query command, please refer to the CLI reference."]}],[{"l":"Alerts","p":["Baselime's alerting feature enables you to set up notifications for when certain conditions are met in your telemetry data. This can be helpful for detecting and responding to issues in your system in real-time."]},{"l":"Setting up alerts","p":["To set up an alert, you will need to specify a query and a threshold. When the result of the query meets the conditions the threshold, the alert will be triggered. You must also specify the frequency to check the query, and time window to consider for the alert.","You can set up alerts using the Baselime CLI with Observability as Code using the Observability Reference Language or the web console. Here is an example of how to set up an alert with ORL:","To create this alert, add it to a any .yml file in your .baselime folder. If you don't have a .baselime folder for your service, create it with baselime init.","Once you have the .baselime folder configured, run the following command to create your alert:"]},{"l":"Receiving alerts","p":["When an alert is triggered, you can choose to receive notifications through a variety of channels, such as email, Slack or webhook."]},{"l":"Tips for effective alerting","p":["Make sure to set appropriate thresholds for your alerts. Setting the threshold too low may result in false positives, while setting it too high may result in missed issues.","Keep alerts specific and actionable: Alerts should be specific and provide clear instructions on what action to take.","Set up alerts for the right things: Make sure to set up alerts for the most important issues that need immediate attention.","Use multiple alerting methods: Use a combination of Slack, email, and webhooks to ensure that you are notified of important issues in a timely manner.","Use alert suppression: Silence repeated alerts to avoid alert fatigue and ensure that you are only notified of important issues.","Consider using webhook alerts to build self-healing systems","Test your alerts to ensure they are working as expected.","Use alert analytics: Use alert analytics to analyze the effectiveness of your alerting strategy and make improvements where necessary.","Regularly review and update alert thresholds and configurations to ensure they are still relevant and effective."]}],[{"l":"Tailing your data","p":["The baselime tail command enables you to stream telemetry data in real time to your terminal. This can be useful for debugging or quickly checking the status of your services.","By default, the baselime tail command will stream all telemetry data for your Baselime environment. You can further filter the data by adding query parameters, such as:","This will only show the events where data.user.id is 123456 and the word error appears in the event.","You can also specify a time range for the data being streamed:","Alternatively, you can define the timerange in relative format","This will stream telemetry data between the specified start and end times.","The baselime tail command can be a useful tool for quickly checking the status of your application and identifying any issues that may be occurring."]}],[{"l":"Reports","p":["Baselime reports are a powerful tool that enable you to compare the state of a service before and after making changes. By incorporating Baselime reports into your CI/CD pipeline, you can see the impact of changes in production. This improves the reliability of your deployments and enables you to build self-healing systems.","For example, if a report after deployment fails, you can roll back or roll forward to ensure the stability of your service.","Here is an example of how you can use the baselime report command in a GitHub Action to compare the state of a service before and after a deployment:","This workflow takes a snapshot with baselime report github before and after running the deployment script ( npm run deploy). The reports are posted on the commit that triggered the workflow. By comparing the two snapshots, you can see how the deployment affected your service and take appropriate action."]},{"l":"Running a report","p":["To run a report, use the baselime report command. By default, this will create a snapshot of all the alerts in the current service, display the results in the terminal, and save them to a file.","To publish a report to GitHub, run:"]}],[{"l":"Baselime CDK Quick Start","p":["Observability is a first class citizen of your infrastructure with Baselime. You can use the AWS CDK to define and automate your observability configurations in Baselime."]},{"l":"Installation","p":["Download the Baselime CDK on npm:@baselime/cdk"]},{"l":"Configuration","p":["Initialise the Baselime CDK with your Baselime API Key.","Get your API Key from the Baselime console. Make sure to select an Admin API Key. Admin API keys have the permissions to create resources in your Baselime account."]},{"l":"Example alert","p":["Set up an alert everytime there's an error in your application logs:","This alert will notify you on Slack when there is an event with LogLevel equal ERROR in your telemetry data."]}],[{"l":"Baselime CDK Queries","p":["Queries are used to retrieve and analyze data from various datasets in order to gain insights from your services."]},{"l":"Query Specification","p":["Heres a sample query in Baselime CDK that uses all of the supported settings for defining queries in Baselime. Use it to get started creating your own queries."]},{"l":"properties","p":["Queries have a set of properties that define the query's characteristics and behavior."]},{"i":"description-optional","l":"description (optional)","p":["The description of the query is a string that provides more information about the query. It can include details about the data being queried, the calculations being performed, and any other relevant information.","Example:"]},{"l":"parameters","p":["The parameters of a query define the datasets to query, the calculations to perform on the data, and any filters or groupings to apply."]},{"i":"datasets-optional","l":"datasets (optional)","p":["The datasets parameter is an array of strings that specify the names of the datasets to query. Baselime supports querying multiple datasets simultaneously, allowing you to analyze data from different sources in a single query. If no datasets are provided, Baselime CDK defaults to lambda-logs.","Example:"]},{"i":"filters-optional","l":"filters (optional)","p":["eq: Equals","Example:","exists: Exists (applies to fields that may or may not exist in the data)","Filters can be used to narrow down the data being analyzed and focus on specific events or attributes.","gt: Greater than","gte: Greater than or equal to","inArray: In (applies to arrays only)","includes: Includes","lt: Less than","lte: Less than or equal to","Moreover, it is possible to add a filter to a query after the query has been initialised.","neq: Does not equal","notExists: Does not exist (applies to fields that may or may not exist in the data)","notInArray: Not in (applies to arrays only)","notIncludes: Does not include","regex: Matches a regular expression","startsWith: Starts with (applies to strings only)","The filters parameter is an array of strings that specify conditions to filter the data by. Baselime CDK provides multiple helper functions to create query filters:"]},{"i":"calculations-optional","l":"calculations (optional)","p":["The calculations parameter is an array of strings that specify the calculations to perform on the data. Baselime CDK provides multiple helper functions to create query calculations:","count: Counts the number of events.","countDistinct: Counts the number of distinct occurences of a field (applies to strings only).","max: returns the maximum value of a field.","min: returns the minimum value of a field.","sum: returns the sum of all values of a field.","avg: returns the average of all values of a field.","median: returns the median of all values of a field.","stdDev: returns the sample standard deviation of a field.","variance: returns the sample variance of a field.","p001, p01, p05, p10, p25, p75, p90, p95, p99, p999: return the specified percentile of all values of a field.","Calculations can be used to perform statistical analysis on the data and derive insights such as the average request duration, the maximum response size, or the 95th percentile of request latencies.","It is possible to pass an optional alias to each of these functions, such that the results are displayed in the Baselime console or CLI using the alias.","Example:"]},{"i":"groupby-optional","l":"groupBy (optional)","p":["The groupBy parameter is an object that specifies how to segment the data by a field. It has the following fields:","value: The field to group the data by","limit: The maximum number of results to return (default: 10)","type: The type of the data field to group by (string, boolean, or number)","orderBy: The calculation to order the results by (default: the first calculation in the query)","order: The order in which to return the results (ASC or DESC, default: DESC)","Grouping the data by a field allows you to segment the results into distinct groups and analyze them separately.","Example:"]},{"i":"needle-optional","l":"needle (optional)","p":["The needle parameter is an object that specifies a search to perform on the data. It has the following fields:","value: The string to search for","matchCase: A boolean indicating whether the search should be case-sensitive(default: false)","isRegex: A boolean indicating whether the search value is a regular expression (default: false)","The needle can be used to find specific set of events or patterns in the data.","Example:"]},{"l":"Adding an alert","p":["Baselime CDK enables you to add an alert to a query. The alert will run the query on a defined schedule and notify you on your preferred channels when specific conditions are met."]},{"l":"Example Queries","p":["Here are example Baselime CDK queries that combine all of the above properties.","This query retrieves data from the otel traces dataset and performs several calculations on the data. It computes the average request duration, maximum response size, and 95th percentile of request latencies for each user ID in the dataset.","It filters the data to only include user IDs with a request duration greater than 500ms, and limits the results to the top 100 user IDs based on the average request duration. The results are ordered by the average request duration in descending order. The query also searches for the word \"error\" in the data and filters the results based on whether or not the word is present.","This Baselime CDK query calculates the total consumed read capacity units for each DynamoDB table in a service. It filters the data to only include events with a metric_name of ConsumedReadCapacityUnits and a unit of Count, and groups the results by TableName. The query returns the top 10 tables with the highest consumed read capacity units."]}],[{"l":"Baselime CDK Alerts","p":["Alerts are used to run a query on a schedule and notify you if a threshold is crossed. Baselime alerts are based on Baselime queries, which gives you you the flexibility to specify alerts on defects or events of interest, and reduce false positives and alert fatigue."]},{"l":"Alert Specification","p":["Heres a sample alert in Baselime CDK that uses all of the supported settings for defining alert in Baselime. Use it to get started creating your own alert."]},{"l":"properties"},{"i":"description-optional","l":"description (optional)","p":["The description of the alert is a string that provides more information about the alert. It can include details about the conditions being monitored and any other relevant information.","Example:"]},{"i":"enabled-optional","l":"enabled (optional)","p":["The enabled property is a boolean that indicates whether the alert is enabled or disabled. If set to true, the alert will be active and trigger notifications when thresholds are met. If set to false, the alert will be inactive and no notifications will be sent.","Example:"]},{"l":"parameters","p":["The parameters of an alert define the query to run, the threshold to evaluate, and the frequency and window for monitoring. query"]},{"l":"query","p":["The query parameter specifies the query to run for monitoring. It can reference an existing query object or include an inline query definition.","Example:","With the inline query the calculation defaults to [calc.count()]","or"]},{"l":"threshold","p":["The threshold parameter specifies the condition to evaluate from the query results. It can use helper functions to create comparisons or calculations, such as gt, lt, eq, count, etc.","Example:"]},{"l":"frequency","p":["The frequency parameter specifies the frequency at which the alert should run the query and evaluate the threshold. It uses a string representation of the frequency, such as '5 mins', '1 hour', '1 day', etc.","Example:"]},{"l":"window","p":["The window parameter specifies the time window to look back for data when evaluating the threshold. It uses a string representation of the time window, such as '10 mins', '1 hour', '1 day', etc.","Example:"]},{"l":"channels","p":["The channels property specifies the destinations to send the alert notifications. It is an array of channel objects, where each object defines the channel type and targets."]},{"l":"type","p":["The type property specifies the type of channel for the alert. Baselime CDK supports various channel types, such as 'email', 'slack', 'webhook', etc."]},{"l":"targets","p":["The targets property specifies the target destinations for the alert notifications. The targets can be specific emails, channels, or URLs depending on the channel type.","Example:","Moreover, you can define a defaultChannel when initialising your Baselime CDK, this channel will be used for all alerts in the service, simplifying your CDK code."]}],[{"l":"Baselime CDK Dashboards","p":["Dashboards give you a birds eye view of a collection of your query results. This can help you look at multiple related graphs on a single page to spot interesting trends.","Dashboards are a collection of queries and charts that you want to keep for future reference. Boards help you visualise multiple queries at once, to spot interesting trends and share your findings with your team."]},{"l":"Dashboard Specification","p":["Heres a sample dashboard in Baselime CDK that uses all of the supported settings for defining dashboard in Baselime. Use it to get started creating your own dashboard."]},{"l":"properties"},{"i":"description-optional","l":"description (optional)","p":["The description of the dashboard is a string that provides more information about the dashboard. It can include high-level details or any other relevant information.","Example:"]},{"l":"parameters","p":["The parameters of a dashboard define the widgets to display on the dashboard."]},{"l":"widgets","p":["The widgets parameter is an array of widget objects that specify the queries to run and the names of the widgets to display on the dashboard. name and description are both optional parameters for a widget.","Example:"]}],[{"l":"Baselime Terraform Provider","p":["Observability is a first class citizen of your infrastructure with Baselime. You can use Terraform to define and automate your observability configurations in Baselime."]},{"l":"Configuration","p":["Use the Baselime Terraform Provider to create and manage your observability resources on Baselime with Terraform.","Get your API Key from the Baselime console. Make sure to select an Admin API Key. Admin API keys have the permissions to create resources in your Baselime account."]},{"l":"Resource types","p":["Query","Dashboard","Alert"]},{"l":"Examples","p":["View examples in the Baselime Terraform Provider GitHub repository."]}],[{"l":"Installing the Baselime CLI","p":["The Baselime CLI enables you to interact with Baselime and your observability data through the command line."]},{"l":"Installing","p":["Installing with Homebrew","Installing with curl","Installing with npm","Optionally, you can download the latest version of the Baselime CLI binary from the releases page on GitHub.","Download the binary for your operating system and architecture (e.g., baselime_linux_x64 or baselime_darwin_x64).","Unzip the tarball with tar -xf baselime-os-arch-version.tar.gz","Make the binary executable with chmod +x baselime.","Move the binary to a directory in your PATH, such as /usr/local/bin, with mv baselime /usr/local/bin/baselime.","On some systems, you might need to run these commands with sudo."]},{"l":"Verifying the installation","p":["Verify that the Baselime CLI was installed with:"]},{"l":"Authenticating the CLI","p":["Before you can use the Baselime CLI, you must authenticate it with your Baselime account.","To use the Baselime CLI in non-interactive evironments, such as in CI pipelines, set the BASELIME_API_KEY environment variable to your Baselime API key and the CLI will use it for all commands."]},{"l":"Updating the Baselime CLI","p":["To update the Baselime CLI to the latest version, use one of the following commands depending on how you originally installed it:","If you installed with brew, run brew upgrade @baselime/cli","If you installed with curl, run baselime upgrade","If you installed with npm, run npm update -g @baselime/cli"]}],[{"l":"Anonymous Telemetry","p":["Baselime collects completely anonymous telemetry data about general CLI usage. Participation in this anonymous program is optional, and you can opt-out if you'd not like to share any information."]},{"i":"how-do-i-opt-out","l":"How do I opt-out?","p":["You can opt out-by running the following command:","You can re-enable telemetry if you'd like to rejoin the program by running."]},{"i":"why-do-we-collect-telemetry-data","l":"Why do we collect telemetry data?","p":["Telemetry data help up to accurately measure the Baselime CLI feature usage, pain points, and customisation across all developers. This data empowers us to build a better product for more developers.","It also allows us to verify if the improvements we make to the Baselime CLI are having a positive impact on the developer experience."]},{"i":"what-is-being-collected","l":"What is being collected?","p":["We measure the following anonymously:","Command invoked (ie. baselime deploy, baselime query, or baselime tail)","Version of Baselime in use","General machine information (e.g. number of CPUs, macOS/Windows/Linux, whether or not the command was run within CI)","An example telemetry event looks like:","These events are then sent to an endpoint hosted on our side."]},{"i":"what-about-sensitive-data-or-secrets","l":"What about sensitive data or secrets?","p":["We do not collect any metrics which may contain sensitive data.","This includes, but is not limited to: environment variables, file paths, contents of files, logs, or serialized errors."]},{"i":"will-the-telemetry-data-be-shared","l":"Will the telemetry data be shared?","p":["The data we collect is completely anonymous, not traceable to the source, and only meaningful in aggregate form.","No data we collect is personally identifiable.","In the future, we plan to share relevant data with the community through public dashboards or reports."]}],[{"l":"baselime connect","p":["Use the baselime connect command to connect your AWS account to Baselime."]}],[{"l":"baselime console","p":["Use the baselime console command to open the Baselime console."]}],[{"l":"baselime iam","p":["Use the baselime iam command to display the currently logged-in user and environment."]}],[{"l":"baselime login","p":["Use the baselime login command to log in your Baselime account and select an environment."]}],[{"l":"baselime logout","p":["Use the baselime logout command to log out of Baselime."]}],[{"l":"baselime mark","p":["Use the baselime mark command to create a marker."]}],[{"l":"baselime query","p":["Use the baselime query command to run a query on your telemetry data data."]}],[{"l":"baselime rehydrate","p":["Use the baselime rehydrate to rehydrate Baselime hot storage with data from your Amazon S3 Bucket."]}],[{"l":"baselime report","p":["Use the baselime report command to generate a report based on your observability data and assess the health and performance of your service."]}],[{"l":"baselime tail","p":["Use the baselime tail command to stream events from your telemetry data in real-time."]}],[{"l":"baselime telemetry","p":["Use the baselime telemetry command to manage the usage telemetry data collected by the Baselime CLI."]}],[{"l":"baselime test","p":["Use the baselime test command to check all the alerts in your current service, display the results in the terminal, and output them to a file."]}],[{"l":"baselime upgrade","p":["Use the baselime upgrade command to upgrade the Baselime CLI to the latest version. This method will work only if you installed the Baselime CLI with curl -s https://get.baselime.io | bash."]}],[{"l":"Data Security","p":["Baselime is committed to ensuring the security and privacy of our users' data. We have implemented a number of measures to ensure that data is encrypted in transit and at rest, and that it is not accessible from the public internet. Here are some of the key data security features of Baselime:"]},{"l":"Data Encryption","p":["All data transferred to and from Baselime is encrypted in transit using industry-standard protocols such as HTTPS and TLS. In addition, all data is encrypted at rest."]},{"l":"Private VPCs and IAM Roles","p":["Baselime runs in private Virtual Private Clouds (VPCs) and utilizes IAM roles to ensure that data is only accessed by authorized users and processes."]},{"l":"No Public Access","p":["Baselime does not expose any data to the public internet. All data is accessed via secure, authenticated channels."]},{"l":"Modern Best Practices","p":["Baselime follows modern best practices for data security, including regularly updating and patching our systems, implementing network segmentation and access controls, and conducting regular security audits and penetration testing."]},{"l":"Data Scrubbing and Obfuscation","p":["Baselime provides tools for scrubbing and obfuscating sensitive data, such as passwords, secrets, and API keys. Users can block or obfuscate specific keys by dataset using the .baselimeignore file. In addition, Baselime automatically scrubs a predefined list of sensitive fields, including \"password\" and \"secret\".","To learn more about how to use these features to protect your data, see the Baselime Telemetry Data Privacy documentation."]},{"l":"Compliance","p":["We're currently working towards compliance with a number of industry-standard security and privacy frameworks, including GDPR, SOC2 and HIPAA. Please contact us for more information on our compliance status."]},{"l":"Support","p":["If you have any questions or concerns about the security of your data in Baselime, please don't hesitate to contact our support team. We are always here to help!"]}],[{"l":"Telemetry Data Privacy","p":["Baselime is designed to help you observe the health and performance of your applications, and part of that involves collecting telemetry data. To ensure the privacy of your data, Baselime provides a number of features that enable you to control which data is collected and how it is used."]},{"l":"Obfuscating Keys","p":["Baselime enables you to obfuscate keys from being ingested into your datasets. This is particularly useful for sensitive information such as passwords, API keys, and other personal data. You can obfuscate keys for a specific dataset in the Baselime console, in the datasets section.","Keep in mind that obfuscating keys is a one-way process, meaning that once a key has been obfuscated, there is no way to recover the original value. Make sure to carefully consider which keys you want to obfuscate."]},{"l":"Automatic scrubbing","p":["Baselime that automatically obfuscate sensitive information from being ingested into the telemetry data by default. This is done to ensure that sensitive data is not accidentally exposed.","The following keys are automatically scrubbed:","password","secret","passwd","api_key","pwd","apikey","access_token","auth","credentials","creds","sourceip","Any nested field in your telemetry data that contains any of these automatically scrubbed keys will be blocked from ingestion by default.","To turn automatic scrubbing on or off for a specific dataset, use the Baselime console, in the datasets section."]}],[{"l":"Connectors","p":["Baselime uses connctors to automatically ingest telemetry data from your cloud environments."]}],[{"l":"AWS Connector on Baselime","p":["The AWS Connector allows you to send data from your AWS resources to Baselime. This includes logs, traces, and metrics. By connecting your AWS account to Baselime, you can get a unified view of your architecture, query your data, and set up alerts."]},{"l":"Setting up the AWS Connector","p":["The connector is an automated flow based on a CloudFormation template.","It can be done using the Baselime CLI or through the web console."]},{"l":"Using the CLI","p":["To connect a cloud account to Baselime using the CLI, run the following command in your terminal","Once you've followed the interactive steps, the CLI will generate a CloudFormation template for you to deploy on your AWS account. FOllow the link in your terminal to deploy the temple on your AWS account.","Once deployed, login in your newly connected environment from the CLI.","The interactive prompt should list your newly connected environment.","Within minutes you should get telemetry data flowing through with the command"]},{"l":"Using the Web Console","p":["Navigate to the Baselime web console and login.","Follow the steps on the homescreen to connect a new AWS Account. Baselime will generate a CloudFormation template for you to deploy on your AWS account.","Once the template is deployed on AWS, return to the Baselime web console and refresh the page. You should see the newly connected AWS environment in the list of connected environment.","Within minutes telemetry data from your AWS environment should start displaying in the events streams in the Baselime web console."]},{"l":"Troubleshooting","p":["If you encounter any issues or error when connecting your AWS environment, please don't hesitate to contact us, or join our Slack community where we are always available to support."]},{"l":"CloudFormation Template","p":["The CloudFormation template is open-source and available here."]},{"l":"Your data","p":["Once connected, Baselime will automatically ingest data from your AWS environment. This includes:","Lambda Logs","API Gateway Logs","Cloudtrail Logs","Cloudwatch Metrics","ECS Logs (through fluentd)","Open Telemetry Metrics","X-Ray Traces","Once ingested, the telemetry data is streamed through a Kinesis Firehose to an Amazon S3 bucket in your AWS account for cold storage. There you can access the raw data and use it for your own purposes.","The default retention period of the telemetry data in your bucket is set to 180 days by default."]}],[{"l":"Baselime CDK","p":["Baselime natively integrates with any AWS CDK application. This enables you to define your alerts and dashboards as code, alongside your application code. You can re-use your observability configurations, enforce consistency and share best practices with your team, in your codebase."]},{"l":"Usage","p":["Install the dependencies.","Initialise @baselime/cdk in your CDK stack."]},{"l":"Instrumenting your application","p":["Here we have an lambda function that creates a subscription. This is a critical flow within the application. We need to know about any problems asap but also the business metrics that it produces can tell us about harder to detect issues in other parts of the system. Using @baselime/cdk we are going to create a comprehensive set of alerts and a dashboard that gives us insight into the business metrics and performance of our application.","In this lambda function we have added structured json logs to each critical path of this application that give us context of what happens. The lambda runtime will also emit START, END, and REPORT logs that we can use to understand the performance of the application."]},{"l":"Catching Errors","p":["The first thing we want to do is set up alerts for any errors in our new lambda function. Our billing team want to be informed about any subscription related errors separately. This can be done by putting a custom target in the channel once the slack integration is set up","This adds a query and alert to your applications service in Baselime that notify you in slack when ever any log messages contain an error or Unhandled Exceptions caught by the lambda runtime. The alerts will check every 30 minutes for any errors.","The billing team come back and explain that they want to see the errors broken down by customer so they can see which customers where effected by the broken code.","This now shows us exactly the customers that where effected by the outage."]},{"l":"Business Metrics","p":["O11y is not just for code errors. It's also about painting a richer picture of your application. Imagine the scenario where your company doesn't start any new subscriptions in a day. This is an example of where having sensible alerts and dashboards for your system metrics can spot issues in your whole application. i.e. maybe the new marketing campaign emails failed or your signup page has a glitch and the submit button has been set to display:hidden;. It's hard to write tests for every possibility but having alerts on key business metrics can give you useful feedback where tests cannot.","To do this we are going to set up a query that tracks the amount of revenue we are taking per hour.","We can then use this query in dashboards and alerts to show the performance of our business.","An alert that warns us if the subscriptions fall bellow the expected level could warn us of a wide range of problems so we are going to set that up like this f"]},{"l":"Conclusion","p":["Baselime CDK is a useful tool to test in prod. It can help catch issues as they happen so you can take effective corrective action, setting it up in your CDK stack is super effective because its now front of mind when designing the infrastructure for your service."]}]]