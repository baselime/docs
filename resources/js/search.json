[[{"l":"Baselime Documentation","p":["To get started, read the quick start guide.","This documentation highlights what Baselime is, how to get it working with your stack and how it can help you discover, investigate, and resolve errors and performance issues before they become problems.","Quick Start Baselime Documentation Analyzing Data in Baselime Data Security"]},{"l":"Support","p":["Join the Baselime Slack Community if you have any questions, or you want to learn and discuss ideas around observability practices."]}],[{"i":"what-is-baselime","l":"What is Baselime?","p":["Baselime is an observability solution built for modern cloud-native environments. It combines logs, metrics, and distributed traces to give you full visibility across your microservices at scale.","Baselime Console"]},{"i":"how-is-baselime-different","l":"How is Baselime different?","p":["Baselime is fundamentally different from most other observability and monitoring providers in 4 key aspects:"]},{"l":"High cardinality and dimentionality","p":["Cardinality and dimentionality are best described using examples. Imagine you log an HTTP request that makes database calls.","High cardinality means that in your logs, you can have a unique userId or requestId(which can take over a million distinct values). Those are high cardinality fields. Baselime enables you to query against any specific value of a high cardinality field so that you can narrow down your search to a specific user or request.","High dimensionality means that in your logs, you can have thousands of possible fields. You can record each HTTP header of your request and the details of each database call. Any log can be a key-value object with thousands of individual keys. Baselime indexes every single one of the keys and enables you to query against every one of them.","From day 0, everything is queriable and searchable, and correlation between data sources is possible. Baselime does not perform any pre-aggregation of data before ingestion; this means you can run arbitrary queries on you telemetry data, and get answers about the state of your application."]},{"l":"Query speed","p":["Baselime is built on top of ClickHouse, the fastest analytics database in the world. When debugging real production outages, the ability to ask questions and get answers fast is most important."]},{"l":"Real-time data ingestion","p":["Baselime ingests data from your application in real-time. Telemetry data is available for you to query or for the real-time alerting within seconds of it being generated by your applications."]},{"l":"Metadata annotations","p":["Baselime automatically adds all the metadata necessary to contextualise your telemetry data: hostname, hostID, serverless function name, service name, cloud account and region, etc. All this data is automatically captured by Baselime. It enables you to efficiently identify patterns based on those parameters automatically.","Moreover, Baselime gives your control over the residency of your data. Either using our backend or a Bring Your Own Backend solution where all the data is stored on your cloud account."]},{"i":"why-baselime","l":"Why Baselime?"},{"l":"Find and solve issues faster","p":["Troubleshoot infrastructure and application issues with high cardinality data and a fast query enginer."]},{"i":"search-anything-anywhere-its-all-indexed","l":"Search anything, anywhere. It's all indexed","p":["Query against any nested field and automatically surface anomalies fast; regardless of how unusual or unique this state of your application is."]},{"l":"Take control of your data and costs","p":["Use our backend or Bring Your Own Backend. Up to 6x more value than incumbents. No per-function pricing, no per-seat pricing, no per-alert pricing. Start at $0 and scale up as your applications grow, with no hidden fees."]}],[{"l":"FAQ"},{"i":"what-is-baselime","l":"What is Baselime?","p":["Baselime is an observability solution that makes observability for cloud-native microservices easy. Baselime covers your logs, metrics, traces in a single solution. Baselime is built on top of ClickHouse, the fastest columnar database in the world."]},{"i":"how-much-does-it-cost","l":"How much does it cost?","p":["Baselime pricing is based on the number of events your systems produce. This scales linearly with the traffic your applications handle. Moreover, Baselime has a full free tier for up to 20M events per month.","Check out our pricing page for more details."]},{"i":"how-does-baselime-count-events-for-billing","l":"How does Baselime count events for billing?","p":["Baselime counts the number of events daily and updates your dashboard accordingly. Baselime does not count Amazon CloudWatch metrics or Amazon CloudTrail logs as part of the monthly event cap. All other events are counted, include the START, END and REPORT log lines from serverless functions."]},{"i":"does-baselime-support-multi-accounts-and-multi-regions","l":"Does Baselime support multi-accounts and multi-regions?","p":["Yes, Baselime supports for multi-account and multi-region setups. When you connect your first cloud account to Baselime, Baselime creats a Baselime environment. You can subsequently add as many new cloud accounts or regions to the Baselime environment. All your telemetry data from those separate accounts and regions will be unified in the Baselime environment."]},{"i":"where-is-my-data-stored","l":"Where is my data stored?","p":["You own your data.","You can select to use either our cloud offering, or our Bring Your Own Backend solution. With Bring Your Own Backend, all the data is stored on your AWS account and your use the Baselime clients to access it."]},{"l":"Cloud offering","p":["All the telemetry data your cloud infrastructure generate is stored in two data tiers:","hot tier: on Baselime AWS accounts in the eu-west-1 region. This data is used for fast questions","cold tier: in an Amazon S3 bucket in your AWS cloud account. This data is used for long terms storage in a resource you own","It is possible to rehydrate data from the cold tier to the hot tier for queriyng historical incidents free of charge."]},{"l":"Bring Your Own Backend","p":["Baselime can integrate with your own backend. As such, all the telemetry data is stored and queried in your cloud account. The enables you to keep maximum flexibility and privacy for storing sensitive data. You will be able to set your own retention periods, your own storage type, and your own privacy settings.","Bring Your Own Backend is available on our Enterprise Plans."]},{"i":"is-my-data-secure","l":"Is my data secure?","p":["Baselime is fully GDPR compliant and your data is stored in data centers that are all SOC2 compliant."]},{"i":"how-can-i-work-with-my-team","l":"How can I work with my team?","p":["Once you sign up to Baselime with your organisation domain email, you can configure Baselime such that anyone with the same email domain can join your workspace.","Moreover, you can invite your teammates individurally. Additionally, every query result, dashboards, an alerts have a unique permalink in Baselime that you can share with your team."]}],[{"l":"Quick Start Guide"},{"i":"step-1-sign-up-for-baselime","l":"Step 1: Sign up for Baselime","p":["Sign up for a free Baselime account in the Baselime console."]},{"i":"step-2-add-an-environment","l":"Step 2: Add an Environment","p":["You can add an environment by connecting your cloud account, or by creating an environment manually to send data manually to Baselime.","Select \"Send data manually\" for this quick start.","Add an Environment"]},{"i":"step-3-send-log-events","l":"Step 3: Send log events","p":["Execute this cURL command to send your first log event to Baselime.","Replace BASELIME_API_KEY with the API key your got from step 2."]},{"i":"step-4-explore-your-data","l":"Step 4: Explore your data","p":["Congratulations! Your first event should be available to query in Baselime. You can start exploring your data using the Baselime console or the Baselime CLI.","Explore how to connect various data sources to Baselime and get full-stack observability across your applications.","Your data in Baselime"]},{"l":"Guides","p":["Sending Data: Learn how to ingest telemetry data from your applications","Analyzing Data: Discover how to use the various interfaces provided by Baselime to analyze and understand your data"]},{"l":"Community","p":["Join the Baselime community to get help with using the platform, share your own experiences, and stay up-to-date with the latest developments.","Slack: Join our Slack community to connect with other Baselime users and get real-time support from the Baselime team","Blog: Read about the latest features, best practices, and more from the Baselime team","Social media: Follow us on Twitter, LinkedIn, and YouTube to stay up-to-date with the latest news and updates from Baselime","We look forward to connecting with you!"]}],[{"l":"Sending Data to Baselime","p":["Baselime supports a variety of data sources, including logs, metrics, traces, and wide events. You can start sending telemetry data to Baselime and improving the performance and reliability of your services with a few steps."]},{"l":"Data Sources"},{"l":"Platforms","p":["Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime"]},{"l":"Languages","p":["Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime Sending Data to Baselime"]},{"l":"Direct Sources","p":["Sending Data to Baselime Sending Data to Baselime"]},{"l":"Best Practices","p":["Correlating logs with traces Enriching Logs for faster debugging Data Validation Sampling"]}],[{"i":"opentelemetry-for-nodejs","l":"OpenTelemetry for Node.js","p":["The Baselime Node.js OpenTelemetry SDK enables you to instrument your Node.js services with OpenTelemetry without the boilerplate of using the OpenTelemetry SDK directly.","This SDK uses OpenTelemetry for JavaScript and provides a layer that facilitates instrumenting your Node.js applications.","If your application is already instrumented with OpenTelemetry, you can start sending your tracing data to Baselime without any additional code changes.","Add the Baselime OpenTelemetry endpoint to your exporter:","Endpoint https://otel.baselime.io/v1/","Header: x-api-key: BASELIME_API_KEY"]},{"l":"Instrumentation"},{"i":"step-1-install-the-sdks","l":"Step 1: Install the SDKs","p":["Install the Baselime Node.js OpenTelemetry SDK."]},{"i":"step-2-initialise-the-tracer","l":"Step 2: Initialise the tracer","p":["Create a tracing.js file"]},{"i":"step-3-set-the-baselime-environment-variables","l":"Step 3: Set the Baselime environment variables","p":["Set the environment variables of your comntainer service to include the Baselime API Key and set the NODE_OPTIONS enviroment variable to preload the OpenTelemetry SDK into your application.","Key","Value","Description","BASELIME_KEY","your-api-key","Get this key from the Baselime console or the Baselime CLI","NODE_OPTIONS","-r ./src/tracing.js","Preloads the OpenTelemetry SDK at startup","Once these steps are completed, distributed traces from your Node.js container applications should be available in Baselime to query via the console or the Baselime CLI.","Example OpenTelemetry Trace"]},{"l":"Configuration","p":["An array of instrumentation options","baselimeKey","collectorUrl","Description","Field","InstrumentationOption[]","instrumentations","namespace","service","string(optional)","The Baselime API key","The BaselimeSDK class of the Baselime Node.js OpenTelemetry SDK takes the following configuration options.","The namespace","The service name","The URL of the collector","Type"]}],[{"i":"opentelemetry-for-nextjs","l":"OpenTelemetry for Next.js","p":["Instrument your Next.js applications with OpenTelemetry using the the Baselime Node.js OpenTelemetry SDK.","If you deploy your Next.js applications on Vercel, install the Vercel Baselime Integration to enable logs in addition to distributed tracing."]},{"l":"Instrumentation","p":["Check out a complete example including Prisma and tRPC in our GitHub Examples Repo."]},{"i":"step-1-install-the-sdk","l":"Step 1: Install the SDK","p":["Install @baselime/node-opentelemetry in your project."]},{"i":"step-2-initialise-the-tracer","l":"Step 2: Initialise the tracer","p":["Create a file instrumentation.ts in the root of your project and add the following code to configure and initialize OpenTelemetry.","If you use a /src folder your project, add the instrumentation.ts file in the /src folder instead of the root folder."]},{"i":"step-3-set-the-baselime-environment-variables","l":"Step 3: Set the Baselime environment variables","p":["Set the BASELIME_KEY environment variable to your Baselime public API Key. Get your pulic API key from the Baselime console."]},{"i":"step-4-enable-nextjs-auto-instrumentation","l":"Step 4. Enable Next.js Auto Instrumentation","p":["Next.js 13.4+ supports auto-instrumentation. Add experimental.instrumentationHook = true to your next.config.js to enable auto-instrumentation of all the requests your app makes to external services.","Once these steps are completed, distributed traces from your Next.js application should be available in Baselime to query via the console or the Baselime CLI.","Example Next.js Trace"]},{"l":"Tracing your tRPC applications","p":["tRPC is a framework that enables you to easily build & consume fully typesafe APIs without schemas or code generation. The Baselime Node OpenTelemetry SDK enables automatically tracing your tRPC applications with its tRPC middleware."]},{"l":"Adding custom OpenTelemetry spans","p":["To add custom spans to your OpenTelemetry traces, install the @opentelemetry/api package.","And manually add spans to your traces."]}],[{"l":"OpenTelemetry for SvelteKit","p":["Instrument your SvelteKit applications with OpenTelemetry using the the Baselime Node.js OpenTelemetry SDK and the SvelteKit OpenTelemetry Middleware.","If you deploy your SvelteKit applications on Vercel, install the Vercel Baselime Integration to enable logs in addition to distributed tracing."]},{"l":"Instrumentation","p":["Check out a complete example in our GitHub Examples Repo."]},{"i":"step-1-install-the-sdk","l":"Step 1: Install the SDK","p":["Install @baselime/node-opentelemetry in your project."]},{"i":"step-2-initialise-the-tracer","l":"Step 2: Initialise the tracer","p":["Create a file instrumentation.ts in the root of your project and add the following code to configure and initialize OpenTelemetry.","If you use a /src folder your project, add the instrumentation.ts file in the /src folder instead of the root folder."]},{"i":"step-3-set-the-baselime-environment-variables","l":"Step 3: Set the Baselime environment variables","p":["Set the BASELIME_KEY environment variable to your Baselime public API Key. Get your pulic API key from the Baselime console."]}],[{"l":"OpenTelemetry for Python","p":["The Baselime Python OpenTelemetry SDK enables you to instrument your Python services with OpenTelemetry without the boilerplate of using the OpenTelemetry SDK directly.","This SDK uses OpenTelemetry for Python and provides a layer that facilitates instrumenting your Python applications.","If your application is already instrumented with OpenTelemetry, you can start sending your tracing data to Baselime without any additional code changes.","Add the Baselime OpenTelemetry endpoint to your exporter:","Endpoint https://otel.baselime.io/v1/","Header: x-api-key: BASELIME_API_KEY"]},{"l":"Instrumentation"},{"i":"step-1-install-the-sdks","l":"Step 1: Install the SDKs","p":["Install the Baselime Python OpenTelemetry SDK."]},{"i":"step-2-install-instrumentations","l":"Step 2: Install Instrumentations","p":["Automatically install instrumentation for the python libraries you use with opentelemetry-bootstrap"]},{"i":"step-3-set-the-baselime-environment-variables","l":"Step 3: Set the Baselime environment variables","p":["Set the environment variables of your comntainer service to include the Baselime API Key"]},{"i":"step-4-run-the-opentelemetry-instrumentation","l":"Step 4: Run the Opentelemetry Instrumentation","p":["Once these steps are completed, distributed traces from your Python container applications should be available in Baselime to query via the console or the Baselime CLI."]},{"l":"Configuration","p":["When running your application locally you can set the environment variable EXPORT_CONSOLE=TRUE to print all the telemetry to the console. This can help make sure you have instrumented your application correctly"]}],[{"l":"OpenTelemetry for Go","p":["The Baselime Go OpenTelemetry SDK enables you to instrument your Go services with OpenTelemetry without the boilerplate of using the OpenTelemetry SDK directly.","This SDK uses OpenTelemetry for Go and provides a layer that facilitates instrumenting your Go applications.","If your application is already instrumented with OpenTelemetry, you can start sending your tracing data to Baselime without any additional code changes.","Add the Baselime OpenTelemetry endpoint to your exporter:","Endpoint https://otel.baselime.io/v1/","Header: x-api-key: BASELIME_API_KEY"]},{"l":"Instrumentation"},{"i":"step-1-install-the-sdks","l":"Step 1: Install the SDKs","p":["Install the Baselime Go OpenTelemetry SDK."]},{"i":"step-2-set-the-baselime-environment-variables","l":"Step 2: Set the Baselime environment variables","p":["Set the environment variables of your comntainer service to include the Baselime API Key"]},{"i":"step-3-add-the-opentelemetry-instrumentation-to-your-application","l":"Step 3: Add the Opentelemetry Instrumentation to your application","p":["Once these steps are completed, distributed traces from your go container applications should be available in Baselime to query via the console or the Baselime CLI.","The BaselimeSDK takes the following configuration options."]},{"l":"Configuration","p":["Field Name","Description","BaselimeApiKey","API key for Baselime service","ServiceName","Name of the service","Namespace","Namespace identifier","CollectorUrl","URL for the data collector","Protocol","Communication protocol (grpc / http)"]},{"l":"Instrumenting Libraries","p":["In Go you have to manually instrument the libraries you use. You can find instrumentation for popular libraries on the go ecosystem registry","Once you have installed the instrumentation you can find the instructions on how to apply it in their github repo, each instrumentation could be slightly different."]}],[{"l":"Baselime Pino Transport","p":["Send structured logs to Baselime with pino and the @baselime/pino-transport.","Don't use this with Vercel, use the native Log Drain Integration instead.","Step 1: Install the Transport","Step 2: Set up the Pino Logger with the Baselime Transport","Get your public BASELIME_API_KEY from the Baselime Console","Step 3: Use the logger"]},{"l":"Configuration","p":["The @baselime/pino-transport takes the following options","Field","Type","Description","baselimeApiKey","string","The Baselime API key","dataset","string(optional)","The dataset name - defaults to pino-logs","service","The service name","namespace","The namespace"]}],[{"l":"React Real User Monitoring","p":["Instrument your React applications with @baselime/react-rum."]},{"l":"Instrumentation","p":["Check out a complete example using Next.js.","Step 1: Install @baselime/react-rum in your project.","Step 2: Add the Baselime Real User Monitoring component at the top level of your application.","Add BaselimeRum to your Root layout.jsx file","Once this is done, all Unhandled exceptions are sent to Baselime"]},{"l":"Web Vitals","p":["Additionally, you can enable capturing web vitals from your React applications. Use the enableWebVitals prop.","Time To First Byte (TTFB)","Largest Contentful Paint (LCP)","First Input Delay (FID)","Cumulative Layout Shift (CLS)"]},{"l":"Error Boundaries","p":["To provide a better UX for end users, use React Error Boundaries.","The BaselimeErrorBoundary catches errors in any of its child components, reports the error to Baselime. It works in conjunction with the BaselimeRum / Component so that all errors are correlated by Page Load, and User Session."]},{"l":"Error Boundary Options","p":["Option","Description","fallback","A React element to be shown when an error occurs.","FallbackComponent","A React component to be used as a fallback when an error occurs.","fallbackRender","A function for rendering the fallback UI when an error occurs.","onError","A callback function to handle errors with the signature (error: Error, info: ErrorInfo) = void.","onReset","A callback function to handle reset events with various reasons.","resetKeys","An array of keys that trigger a reset when changed.","You can use these options when creating an BaselimeErrorBoundary component, and choose which one best fits your needs based on how you want to handle errors and fallback UI rendering."]},{"l":"Capture Exceptions","p":["Error Boundaries do not catch errors inside event handlers. To catch Exceptions"]},{"l":"Custom Events","p":["Capture custom events for analytics and monitoring. Like logs but with all the power of Baselime.","sendEvent(message: string, payload)"]},{"l":"Setting the active user","p":["To set the User from another component then call"]},{"l":"Using your data","p":["Once the data is captured, you can query, search and analyse your data in the Baselime console. You can create dashboards and alerts based on the Real User Monitoring metrics."]}],[{"l":"Baselime Winston Transport","p":["Send structured logs to Baselime with winston and the @baselime/winston-transport.","Step 1: Install the Transport","Step 2: Set up the Winston Logger with the Baselime Transport.","Get your public BASELIME_API_KEY from the Baselime Console","Step 3: Use the logger"]},{"l":"Configuration","p":["The @baselime/winston-transport takes the following options","Field","Type","Description","baselimeApiKey","string","The Baselime API key","dataset","string(optional)","The dataset name - defaults to winston-logs","service","The service name","namespace","The namespace"]}],[{"l":"AWS","p":["Baselime provides observability for applications deployed on AWS, with a focus on modern serverless and container serices such as AWS Lambda, Amazon ECS and AWS AppRunner.","To connect your AWS account to Baselime, log in the Baselime console. Create a new environment, select \"Connect AWS account\" and follow the instructions. You will be prompted to deploy a CloudFormation stack onto your AWS account. The stack is open-source and does not have any impact on your AWS bill."]},{"l":"AWS Data Sources","p":["The following sections highlight how Baselime captures telemetry data for supported AWS services.","AWS AWS AWS AWS AWS AWS AWS"]}],[{"l":"AWS Lambda","p":["Baselime automatically captures logs from your AWS Lambda functions through Amazon CloudWatch when you connect your AWS account. Moreover, you can instrument your AWS Lambda functions with OpenTelemetry for distributed tracing.","Logs Distributed Tracing"]}],[{"l":"AWS Lambda Logs","p":["Once you connect your AWS account to Baselime, it automatically creates CloudWatch Logs subscription filters to ingest logs from your AWS Lambda functions.","Baselime automatically captures logs for newly created AWS Lambda functions, and enables you to query and visualise logs across multiple log groups and log streams.","It is possible to send logs from AWS Lambda functions to Baselime directly using the Baselime AWS Lambda Extension, and bypass Amazon CloudWatch for cost considerations."]},{"l":"How it works","p":["Once Baselime is connected to an AWS Account, it automatically creates Logs subscription filters for all the AWS Lambda functions in the account. Log subscription filters enable Baselime to asynchronously ingest logs from the AWS Lambda functions through Amazon CloudWatch, without any impact on the performance of the AWS Lambda functions.","Sending Lambda Logs to Baselime","Moreover, Baselime automatically creates new subscription filters for newly deployed AWS Lambda functions. Baselime listens to new AWS Lambda events in Amazon CloudTrail and creates subscription filters for newly created AWS Lambda functions.","AWS Lambda Logs in Baselime"]},{"l":"Logs using the AWS Lambda Extension","p":["This section is relevant only if you want to disable logs from Amazon CloudWatch and send logs from your AWS Lambda functions directly to Baselime.","For use-cases where you want to by-pass Amazon CloudWatch and send logs directly to Baselime from your AWS Lambda functions, use the Baselime AWS Lambda Extension.","The Baselime AWS Lambda Extension listens to invocation events and collects telemetry data, such as logs and runtime metrics."]},{"l":"Instrumenting","p":["To instrument your AWS Lambda Functions with the Baselime AWS Lambda Extension, add the extension as an AWS Lambda Layer.","It is required to add your public Baselime API key to your functions as an environment variable.","Where the BASELIME_KEY is your public Baselime API Key and the BASELIME_LAMBDA_LAYER_ARN is the ARN of the Baselime AWS Lambda extension in your region.","The Baselime AWS Lambda Extension is language agnostic and is compressed as a single binary, to minimise its impact cold-starts and performance.","Using the Baselime Lambda Extension","All the logs and metrics from your AWS Lambda function is collected asynchronously from your invocation, and sent to the Baselime backend in a separate process from your invocation, with no impact on the latency your users experience."]},{"l":"Configuration","p":["When using the Baselime AWS Lambda Extension, it is not necessary to use Amazon CloudWatch for AWS Lambda logs. To disable Amazon Cloudwatch logs, add an explicit deny IAM policy that prevents the creation of log streams and log events for your function."]},{"l":"Logging best practices","p":["In order to get the most out of Baselime, we recommend adding two log messages to all your AWS Lambda functions:","the event which triggered your Lambda function","the response your Lambda function returns","These can be added as follows:","To facilitate this in Node.js runtimes, we maintain a custom logger well suited for AWS Lambda.","It's a 2.5kb JavaScript file with 0 dependencies, and does not have any significant impact on performance or cold-starts.","It also provides an interface to be used as a middy middleware."]},{"l":"Logging format","p":["We recommend using structured logging across your application, preferably in JSON format. Feel free to use your favourite logging library; we recommend:","Baselime Lambda Logger for Node.js","AWS Lambda Power Tools","It is particularly important to format errors and exception correctly to appropriately log stack traces.","or with the Baselime Lambda Logger for Node.js:"]},{"l":"Discovered Keys","p":["Baselime automatically discovers key - value pairs from your AWS Lambda logs. This enables you to run complex queries and setup alerts on data that otherwise would be difficult to work with from the AWS Lambda service. For instance, from the discovered keys from the Lambda logs, it's possible to set alerts on the maximum memory used by lambda functions during execution, compared to the amount of memory they are assigned at deployment time."]},{"l":"Lambda Discovered Keys","p":["The Lambda service automatically writes logs at the start and end of every function invocation. These logs are parsed as events in Baselime, and keys are automatically discovered from those messages."]},{"l":"START Log Message","p":["The following keys are discovered from the START message:","@type: is always START","@requestId: the request ID of the Lambda invocation","@version: the invoked version of the Lambda function"]},{"l":"END Log Message","p":["The following keys are discovered from the END message:","@type: is always END","@requestId: the request ID of the Lambda invocation"]},{"l":"REPORT Log Message","p":["The following keys are discovered from the REPORT message:","@type: is always REPORT","@requestId: the request ID of the Lambda invocation","@duration: the duration in milliseconds","@billedDuration: the billed duration in milliseconds","@memorySize: the total memory available to the invocation, in MB","@maxMemoryUsed: the max memory used, in MB","@initDuration: the duration of the lambda initialisation in milliseconds (cold starts)","If the Lambda function is instrumented with XRAY, additional keys are discovered:","@xRAYTraceId: the XRAY trace ID","@segmentId: the XRAY segment ID","@sampled: always true"]},{"l":"Timeout Invocations","p":["If your async Lambda invocation times out, Additional keys are automatically discovered:","@timedOut: always true","@timeout: the duration after which the invocation timed-out in seconds","@message: always Task timed out after {@timeout} seconds","@timestamp: the timestamp at the moment the invocation timed out."]},{"i":"consolelog-log-message","l":"console.log Log Message","p":["For Node.js environments, AWS Lambda uses a modified version of console.log(and other console logging functions) to write to stdout and stderr. These add fields to the log message which are parsed as follows:","@timestamp: the timestamp at the moment the log message was written","@requestId: the request ID of the Lambda invocation","LogLevel: the log level ( INFO, DEBUG, WARN, ERROR)","message: the log string","If the message in @message is a valid JSON object, Baselime will parse it, otherwise it will be considered a string."]},{"l":"Troubleshooting","p":["If you're having trouble sending data from your AWS Lambda logs to Baselime, here are a few things to check:","Verify that your AWS account is correctly connected to Baselime and you receive data in other datasets such as CloudWatch Metrics or CloudTrail Events","Check that your Lambda functions are not already using the maximum number of subscription filters allowed per log group. AWS limits each log group to 2 subscription filters at most. If you're already at the limit, you can remove subscription filters with the cloudwatch-subscription-filters-remover to delete the ones you don't need anymore.","Make sure that your AWS Lambda functions are being invoked and you can view the logs in the CloudWatch section of the AWS Console"]}],[{"l":"OpenTelemetry for AWS Lambda","p":["To automatically instrument your AWS Lambda functions with the Baselime Node.js OpenTelemetry tracer for AWS Lambda, set the following tag to your AWS Lambda functions: baselime:tracing=true.","AWS Lambda Tracing","To add the Baselime tag to all your AWS Lambda functions in a service or stack add this line to your AWS CDK code.","To add the Baselime tag to all your AWS Lambda functions in a service or stack add this line to your sst.config.ts file.","To add the Baselime tag to all your AWS Lambda functions in a add this snippet to your serverless.yml file.","To add the Baselime tag to all your AWS Lambda functions in a add this snippet to your AWS SAM configuration file.","Other observability tool layers and tags can adversely interact with the Baselime OpenTelemetry layer. We recommend to disable all other observability layers and tags before instrumenting your AWS Lambda functions with the Baselime OpenTelemetry layer. Failing to do so could result in down-time."]},{"l":"Runtimes","p":["OpenTelemetry for AWS Lambda OpenTelemetry for AWS Lambda"]},{"l":"Remove OpenTelemetry Instrumentation","p":["To remove the OpenTelemetry instrumentation from your AWS Lambda functions, remove the baselime:tracing=true tag from the function and Baselime will revert the function to un-instrumentate state."]},{"l":"Sending data to another OpenTelemetry backend","p":["OpenTelemetry is an open standard, and you can use the Baselime Node.js OpenTelemetry tracer for AWS Lambda to send telemetry data to another backend of your choice.","Set environment variable COLLECTOR_URL to your observability backend."]}],[{"i":"opentelemetry-for-nodejs-on-aws-lambda","l":"OpenTelemetry for Node.js on AWS Lambda","p":["The Baselime Node.js OpenTelemetry tracer for AWS Lambda instruments your Node.js AWS Lambda functions with OpenTelemetry and automatically sends OpenTelemetry traces to Baselime. This is the most powerful and flexible way to instrument your Node.js AWS Lambda functions."]},{"l":"Automatic Instrumentation","p":["To automatically instrument your AWS Lambda functions with the Baselime Node.js OpenTelemetry tracer for AWS Lambda, set the following tag to your AWS Lambda functions: baselime:tracing=true.","For detailed instructions on how to add the tag to for your framework go to the OpenTelemetry for AWS Lambda Guide"]},{"l":"Adding custom OpenTelemetry spans","p":["To add custom spans to your OpenTelemetry traces, install the @opentelemetry/api package.","And manually add spans to your traces."]},{"l":"Tracing AWS SDK v3","p":["If you bundle the AWS SDK v3 by default it is not traced. For CommonJS builds you can enable tracing with the following esbuild settings","mark @smithy/middleware-stack and @aws-sdk/middleware-stack as external","Ensure these packages are installed into the node_modules folder of your lambda","These packages are both extremely small and removing these from your bundle can also decrease your coldstarts","Add the following config to your lambda.NodejsFunction settings","To add the config globally to your sst.config.ts file.","If using the serverless-esbuild plugin set the following options in your serverless.yml","OpenTelemetry is an open standard, and you can use the Baselime Node.js OpenTelemetry tracer for AWS Lambda to send telemetry data to another backend of your choice.","Set environment variable COLLECTOR_URL to your observability backend.","The AWS JS SDK v2 can result in errors when interacting with OpenTelemetry during automatic request retries. This is the result of trace headers changing between retries and failing the signing verification processes. We've submitted a Pull Request to the AWS JS SDK and will be updating accordingly.","To prevent this issue from arising, add the code snippet below to your code."]}],[{"l":"OpenTelemetry for Python on AWS Lambda","p":["The Baselime Python OpenTelemetry tracer for AWS Lambda instruments your Python AWS Lambda functions with OpenTelemetry and automatically sends OpenTelemetry traces to Baselime. This is the most powerful and flexible way to instrument your Python AWS Lambda functions."]},{"l":"Automatic Instrumentation","p":["To automatically instrument your AWS Lambda functions with the Baselime Python OpenTelemetry tracer for AWS Lambda, set the following tag to your AWS Lambda functions: baselime:tracing=true.","For detailed instructions on how to add the tag to for your framework go to the OpenTelemetry for AWS Lambda Guide"]},{"l":"Adding custom OpenTelemetry spans","p":["To add custom spans to your OpenTelemetry traces, install the opentelemetry-api package.","And manually add spans to your traces."]}],[{"l":"Amazon ECS Container Logs","p":["This page describes how to collect application container logs from Amazon ECS clusters launched with AWS ECS. Baselime supports to ways to get Amazon ECS logs:","using Amazon CloudWatch logs","using AWS FireLens."]},{"l":"Using Amazon CloudWatch logs","p":["If your ECS containers already publish logs to Amazon CloudWatch logs, Baselime automatically captures those logs using log subscription filters. There is no additional setup required.","Baselime also listens to newly deployed Amazon ECS containers and creates log subscription filters for those as soon as they are created."]},{"l":"Using AWS Firelens","p":["If you ECS containers don't publish logs to Amazon CloudWatch logs, you can send logs from your containers directly to Baselime using Firelens."]},{"l":"How it works","p":["FireLens is an Amazon ECS native log router that enables you to send logs from your containerized applications to different destinations, including Baselime. By adding the FireLens sidecar to your task definitions, you can configure and route your container logs to different destinations without modifying your application code.","Sending ECS Logs to Baselime","Each of your ECS tasks can take a sidecar container running the FireLens log driver that will forward all the logs from the containers to Baselime."]},{"l":"Configuring your ECS Tasks"},{"i":"step-1-obtaining-your-baselime-api-key","l":"Step 1: Obtaining your Baselime API Key","p":["You can get your public Baselime API key in the Baselime console from the Baselime CLI.","In the following instructions we will use BASELIME_API_KEY to refer to your Baselime API key."]},{"i":"step-2-adding-the-firelens-sidecar-to-your-task-definitions","l":"Step 2: Adding the FireLens sidecar to your task definitions","p":["Adding the FireLens sidecar to your task definitions is a straightforward process that can be accomplished using various Infrastructure as Code solutions or manually in the console.","Add the Baselime ECS endpoint to your FireLens configuration:","Endpoint ecs-logs-ingest.baselime.io","Header: x-api-key BASELIME_API_KEY","Amazom ECS Logs in Baselime"]},{"l":"Troubleshooting","p":["If you're having trouble sending data from your AWS ECS logs to Baselime, here are a few things to check:","Verify that you're using the correct API key and host in the FireLens configuration","Make sure that your containers are receiving traffic and are writing logs to either stdout or stderr","Check the logs of the FireLens container to look for any anomaly"]}],[{"l":"AWS X-Ray Traces","p":["AWS X-Ray enables developers to generate and collect traces across their distributed services. In order to gain visibility into their applications, developers can use AWS X-Ray to trace requests as they travel through their application, and collect data about the performance of their application.","Baselime enables you to ingest this tracing data and make it available for analysis and troubleshooting.","AWS X-Ray trace diagram in Baselime AWS X-Ray trace waterfall in Baselime"]},{"l":"How it works","p":["Once Baselime is connected to an AWS Account, it will periodically poll your AWS account for new traces and automatically ingest them into your Baselime dataset.","Sending X-Ray Traces to Baselime"]},{"l":"Troubleshooting","p":["If you're having trouble sending data from AWS X-Ray to Baselime, here are a few things to check:","Verify that your AWS account is correctly connected to Baselime and you receive data in other datasets such as CloudWatch Metrics or CloudTrail Events","Check that the Baselime IAM user has the appropriate permissions to access AWS X-Ray","Make sure that your applications emit X-Ray traces and you can view the traces in the X-Ray section of the AWS Console","Baselime will ingest traces emmitted by the AWS X-ray service. To capture HTTP calls or AWS Service calls, you must manually instrument your code with the AWS X-Ray SDK. Read more in the AWS X-Ray docs."]}],[{"l":"Amazon API Gateway Logs","p":["Once you connect your AWS account to Baselime, Baselime automatically create CloudWatch Logs subscription filters to automatically ingest logs from your Amazon API Gateways."]},{"l":"Setup","p":["Baselime can ingest logs only for Amazon API Gateways where access logs are appropriately configured.","We recommend this configuration for Amazon API Gateway logs:","It is possible to enable Amazon API Gateway access logs from your favourite Infrastructure as Code tool, using the CLI or in the AWS console. Below is an example of how to enable Amazon API Gateway logs using the serverless framework."]},{"l":"How it works","p":["Once Baselime is connected to your AWS Account, it automatically creates Logs subscription filters for all the Amazon API Gateways in the account.","Sending API Gateway Logs to Baselime","Moreover, Baselime automatically creates new subscription filters for newly deployed Amazon API Gateways. Baselime listens to new API Gateway events in Amazon CloudTrail and creates subscription filters for newly created Amazon API Gateways."]}],[{"l":"AWS App Runner Logs","p":["Once you connect your AWS account to Baselime, Baselime automatically create CloudWatch Logs subscription filters to automatically ingest logs from your AWS App Runner logs."]},{"l":"How it works","p":["Once Baselime is connected to your AWS Account, it automatically creates Logs subscription filters for all the AWS App Runner services in the account. AWS App Runner automatically creates two log groups for each service:","/aws/apprunner/service-name/unique-id/application: the logs from the container running","/aws/apprunner/service-name/unique-id/service: the internal logs of the AWS App Runner service, typically deployment logs","Baselime create subscription filters for the log groups ending in /application: the logs from the container.","Sending AWS App Runner logs to Baselime","Moreover, Baselime automatically creates new subscription filters for newly deployed AWS App Runner services. Baselime listens to new App Runner events in Amazon CloudTrail and creates subscription filters for newly created AWS App Runner services."]},{"l":"Troubleshooting","p":["If you're having trouble sending data from your AWS App Runner logs to Baselime, here are a few things to check:","Verify that your AWS account is correctly connected to Baselime and you receive data in other datasets such as CloudWatch Metrics or CloudTrail Events","Check that your App Runner services functions are not already using the maximum number of subscription filters allowed per log group. AWS limits each log group to 2 subscription filters at most. If you're already at the limit, you can remove subscription filters with the cloudwatch-subscription-filters-remover to delete the ones you don't need anymore.","Make sure that your AWS App Runner services are being live and you can view the logs in the CloudWatch section of the AWS Console."]}],[{"l":"Amazon CloudTrail","p":["Baselime automatically ingests Amazon CloudTrail events when you connect your AWS account. Baselime will automatically create a new Amazon CloudTrail trail and an Amazon S3 bucket, and configure both to send data to your Baselime account. No additional setup is required.","Once connected, Amazon CloudTrail events will be sent to Baselime and become available for querying."]},{"i":"why-amazon-cloudtrail-","l":"Why Amazon CloudTrail ?","p":["Amazon CloudTrail is a service provided by AWS that records API activity in your AWS account. This data can be used to track changes to your resources, troubleshoot issues, and improve security.","By sending Amazon CloudTrail events to Baselime, you can use our query and visualization tools to analyze and understand your API activity. You can also set up alerts to be notified of specific API activity or trends.","With Amazon CloudTrail events in Baselime, you can gain a deeper understanding of your AWS API activity and use that knowledge to improve the security and reliability of your applications."]},{"l":"How it works","p":["Amazon CloudTrail periodically writes trail data in a pre-configured Amazon S3 bucket in your AWS account. Once the data is written, an Amazon SNS topic is triggered.","Baselime configures this Amazon SNS to invoke an AWS Lambda function. This function reads the data from the bucket and sends it to the Baselime backend.","Sending CloudTrail data to Baselime"]},{"l":"Amazon CloudTrail management events","p":["Amazon CloudTrail events fall into multiple categories, and Baselime automatically ingests CloudTrail management events. Please refer to the complete CloudTrail docs for further details on the CloudTrail concepts."]}],[{"l":"Amazon CloudWatch Metrics","p":["Baselime automatically collects Amazon CloudWatch Metrics from your AWS account. Once you connect your AWS account to Baselime, the necessary resources including a CloudWatch Metrics Stream and a Kinesis Firehose will be automatically created and configured. No additional setup or configuration is required."]},{"i":"why-amazon-cloudwatch-metrics-","l":"Why Amazon CloudWatch Metrics ?","p":["Amazon CloudWatch is a monitoring service provided by AWS that enables you to collect and track metrics for your AWS resources and applications. Metrics are important as they provide insight into the performance and behavior of your applications and the underlying infrastructure.","Amazon CloudWatch Metrics can help you identify issues such as high error rates and latencies, which can help improve the overall reliability and scalability of your applications.","Amazon CloudWatch Metrics cover all aspects of your architecture automatically, from DynamoDB tables to S3 buckets and SQS Queues."]},{"l":"How it works","p":["Once Baselime is connected to an AWS Account, it automatically created the telemetry pipeline for ingesting Amazon CloudWatch metrics into Baselime. The pipeline comprises a CloudWatch Metrics Stream, a Kinesis Firehose and all IAM roles and permissions associated.","This pipeline automatically and continuously sends metrics from your AWS account to Baselime.","Sending Amazon CloudWatch Metrics to Baselime","Amazon CloudWatch Metrics Stream might incur a minimal cost on your AWS account. AWS charges $0.003 per 1,000 metric updates. Refer to the AWS docs for more details."]},{"l":"Custom Amazon CloudWatch Metrics","p":["Baselime automatically ingests all metrics published to Amazon CloudWatch. This includes both standard Amazon CloudWatch metrics and any custom metrics that you may have created.","There is no need to manually configure or set up anything to start ingesting custom Amazon CloudWatch metrics. Once your AWS account is connected, all metrics will be available for querying in Baselime."]},{"l":"Querying Amazon CloudWatch Metrics","p":["Once your AWS account is connected to Baselime, you can use any of the our clients to visualize and query your Amazon CloudWatch Metrics. You'll have access to all the metrics available in your AWS account, and you can filter and aggregate the data in near real-time."]},{"l":"Troubleshooting","p":["If you're having trouble sending metrics from Amazon CloudWatch to Baselime, here are a few things to check:","Verify that your AWS account is correctly connected to Baselime and you receive data in other datasets such as AWS Lambda Logs or CloudTrail Events","Check that the Kinesis Firehose created in your AWS account as part of the Baselime connection has the appropriate API key to connect with the Baselime backend. If the API key is missing, please contact us."]}],[{"l":"Vercel","p":["Vercel is a cloud platform for hosting and deploying web applications and websites. It is designed to make the process of deploying, scaling, and managing web apps as simple and efficient as possible. Vercel offers a variety of features and tools for web developers.","For distributed tracing on Vercel, check out OpenTelemetry for Next.js."]},{"l":"Baselime Integration","p":["Baselime provides advanced observability capabilities for applications running on Vercel.","Install the integration for free on the Vercel marketplace and start observing your Vercel apps in minutes."]},{"l":"How it works","p":["When you install the Baselime integration on the Vercel Marketplace, Baselime automatically creates a log drain on your Vercel account to start streaming all your logs in real-time.","Once Baselime receives your data, we automatically discover all your Vercel apps and ingests all your logs into three datasets:","vercel-build: logs from your Vercel build steps","vercel-edge: logs from Vercel Edge functions","vercel-functions: logs from Vercel functions such as API routes","The logs are separated in multiple datasets to give you a complete view of your Vercel applications."]},{"l":"Using the Vercel integration","p":["All the logs from your Vercel apps are streamed to Baselime. You can search, query or tail your logs from the console and the CLI. You can create alerts from derived metrics from your logs. You can use our dashboard templates to create dashboards based on your Vercel logs, and modify them at will."]}],[{"l":"Cloudflare","p":["Cloudflare is an edge platform that enabled developers to build serverless applications and deploy instantly across the globe for exceptional performance, reliability, and scale."]},{"l":"Data sources","p":["Depending on your use of Cloudflare services, you can send events and logs to Baselime from multiple sources.","Cloudflare Cloudflare Cloudflare Cloudflare"]}],[{"l":"Using Cloudflare Logpush","p":["Cloudflare Logpush is a service provided by Cloudflare that enables you to stream your Cloudflare Worker Trace Event Logs to Baselime.","Cloudflare Logpush is available only to accounts subscribed to the Cloudflare Workers Paid Plan","Cloudflare Logpush is not available for Cloudflare Pages. For Cloudflare pages, please refer to the Cloudflare Pages section."]},{"l":"Usage","p":["Baselime connects to your Cloudflare account and enables Logpush in a few steps:"]},{"l":"1. Create an API Token","p":["To get started, you need to create an API token for your Cloudflare account. This token will enable Baselime to access create the Logpush and add metadata to your events once they are ingested into Baselime.","Create a user API token with the following permissions from the Cloudflare Dashboard:","Logs - Edit: This permission is required to set up logpush configurations to collect logs from Cloudflare.","Account Settings - Read: This permission is needed to list the accounts and add them to Baselime automatically.","Worker Scripts - Edit: This permission is needed to list the Workers add them to your Baselime Services and enable LogPush.","Select all the Cloudflare accounts you want to observe in Baselime. Cloudflare Token Creation","Learn more about API tokens in the Cloudflare Docs"]},{"l":"2. Connect Your Cloudflare Account to Baselime","p":["Use the API Token you created in the previous step to connect your Cloudflare account to Baselime in the Baselime console.","Step 1: Create a new environment","Add Environment","Step 2: Add the API token you created in the previous step and connect your Cloudflare account.","Add your API Token"]},{"l":"3. Enable Logpush on Your Cloudflare Workers","p":["To complete the setup, it's necessary to enable Logpush on your Cloudflare workers.","Add logpush = true to the top level section of your Workers wrangler.toml file","Learn more about enabling Logpush on your Cloudflare workers."]},{"l":"4. Using the Cloudflare Workers Logpush integration","p":["Once you've connected your Cloudflare account to Baselime, all your Workers Trace Events will be available in Baselime. You can search, query or tail your logs from the console and the CLI. You can create alerts from derived metrics from your logs. You can use our dashboard templates to create dashboards based on your Cloudflare events, and modify them at will.","Due to limitations in Cloudflare your duration is inferred from the last log of a request. If a request does not have any requests this duration will be set at 1ms. To resolve this add a log message as the last step of your invocation."]}],[{"l":"OpenTelemetry for Cloudflare Workers","p":["Instrument your Cloudflare Worker applications with OpenTelemetry using the the otel-cf-workers SDK."]},{"l":"Instrumentation"},{"i":"step-1-install-the-sdk","l":"Step 1: Install the SDK","p":["Install @microlabs/otel-cf-workers in your project."]},{"i":"step-2-add-nodejs-compatibility-flags","l":"Step 2: Add Node.js Compatibility Flags","p":["OpenTelemetry requires the Node.js Compatibility flag is enabled at the top level of your wrangler.toml"]},{"i":"step-3-configure-the-tracer","l":"Step 3: Configure the tracer","p":["In your Cloudflare worker file, add the following configuration code to configure OpenTelemetry."]},{"i":"step-4-set-the-baselime-environment-variables","l":"Step 4: Set the Baselime environment variables","p":["In your Cloudflare Workers Secret Configuration add the BASELIME_API_KEY.","To enable tracing for local dev add your BASELIME_API_KEY to your .dev.vars file","In your wrangler.toml file set the SERVICE_NAME variable","Get your pulic BASELIME_API_KEY from the Baselime console.","Once these steps are completed, distributed traces from your Cloudflare workers application should be available in Baselime to query via the console or the Baselime CLI.","Example Cloudflare Worker Trace"]},{"l":"Adding custom OpenTelemetry spans","p":["To add custom spans to your OpenTelemetry traces, install the @opentelemetry/api package.","And manually add spans to your traces."]},{"l":"Special Thanks","p":["This is powered by otel-cf-workers developed by Erwin van der Koogh. It's a fantastic vendor agnostic OpenTelemetry SDK for Cloudflare Workers and you should check it out."]}],[{"l":"Edge Logger","p":["Cloudflare Logpush is not available in all Cloudflare edge environments. In those environments, it's necessary to emit logs from within the process. The Baselime Edge Logger enables you to send logs from your Cloudflare edge environments to Baselime regardless of the platform.","It enables logging from:","Cloudlare Workers","Cloudflare Pages Functions","Cloudflare Pages Middleware"]},{"l":"Usage","p":["Step 1: Install the @baselime/edge-logger package.","Step 2: Add the BASELIME_API_KEY to your your environment variables","Get your public BASELIME_API_KEY from the Baselime console","Step 3: Use the logger"]},{"l":"Supported methods"},{"l":"Local Development","p":["To get logs appropriately formatted in your local development environment using wrangler, add the IS_LOCAL_MODE environment variable to your .dev.var file.","And use it when configurting the BaselimeLogger.","Local development mode is disabled by default to improve performance."]},{"l":"Configuration","p":["API key for authentication","apiKey","boolean(optional)","ctx","dataset","Dataset name","Description","Execution context","ExecutionContext","flushAfterLogs","flushAfterMs","Indicates if it's for local development","isLocalDev","namespace","number(optional)","Property","Request ID","requestId","service","Service name","string","string(optional)","The BaselimeLogger class takes the following configuration options","Threshold number of logs to flush","Type","Wait time to flush the logs to Baselime"]}],[{"l":"Cloudflare Pages","p":["Cloudflare Pages is a frontend app development platform. Baselime enabled your to capture the server-side logs of your applications deployed on Cloudflare pages.","You can setup logs for Cloudflare Pages Functions in 4 steps.","Step 1: Install the @baselime/edge-logger package.","Step 2: Add the logger to your server-side code in the functions directory","Remember to call logger.flush(), otherwise the execution will terminate before logs are forwarded to Baselime.","Step 3: Add the BASELIME_API_KEY environment variable to your Cloudflare pages settings and deploy your application","Get your public BASELIME_API_KEY from the Baselime Console","Add Env to Cloudflare Pages","Step 4: View your logs in the Baselime Console"]},{"l":"Special cases","p":["There are special cases for instrumenting applications on Cloudflare Pages depending on the web framework."]},{"l":"SvelteKit","p":["Additional steps are necessary to instrument applications developed with SvelteKit.","Step 1: Update the build and deploy scripts in your project package.json","Step 2: Add the Baselime logger to your hook.server.js file","Step 3: Access the Baselime logger in the server-side code"]}],[{"l":"OpenTelemetry","p":["If your codebase is already instrumented with OpenTelemetry, you can start sending your traces, metrics and logs to Baselime today.","Step 1: Get BASELIME_API_KEY from the Baselime console.","Step 2: Set the headers","Step 3: Set exporter endpoint","Endpoint otel.baselime.io/v1/","Endpoint otel-ingest.baselime.io:4317"]},{"l":"Baselime Opentelemetry for Platforms","p":["OpenTelemetry OpenTelemetry"]},{"l":"Baselime Opentelemetry Distros","p":["OpenTelemetry OpenTelemetry OpenTelemetry OpenTelemetry"]},{"l":"AWS PrivateLink","p":["Baselime supports AWS PrivateLink for OpenTelemetry. OpenTelemetry"]},{"l":"Language APIs and SDKs","p":["Consult the OTEL documentation to find support for traces, metrics and logs for your languages"]}],[{"l":"AWS PrivateLink for OpenTelemetry","p":["Baselime supports AWS PrivateLink, enabling you to securely send the data directly from your VPC to Baselime's platform without exposing your data to the public internet."]},{"l":"How to set it up","p":["Navigate to \"VPC\" > \"Endpoints\" > \"Create Endpoint\"","Select \"PrivateLink\" as the service category.","Search for \"todo\" in the service name.","Select the VPC and subnets you want to associate with the endpoint.","Create a security group for your endpoint.","Make sure the security group allows outbound traffic to CIDR of the VPC or specific subnet of that VPC you selected in the previous step.","Make sure the security group allows inbound traffic from CIDR of the VPC or specific subnet of that VPC you selected in the previous step.","Click on \"Create Endpoint\".","Wait for the endpoint to be created and accepted by Baselime.","Once accepted navigate to \"VPC\" > \"Endpoints\" and select the endpoint you just created.","\"Actions\" > \"Modify private DNS name\" > Tick \"Enable private DNS names\" > \"Save changes\"","Creating VPC Endpoint","Endpoint service name com.amazonaws.vpce.eu-west-1.vpce-svc-03611009d136b2d65","Use endpoint otel-ingest.baselime.io instead of otel.baselime.io for both HTTP and gRPC when using PrivateLink","After about 60 seconds all your traffic to otel-ingest.baselime.io will be routed through the PrivateLink."]},{"l":"How it works"},{"l":"Without PrivateLink Endpoint","p":["When using Baselime without a PrivateLink endpoint, the DNS otel-ingest.baslime.io resolves to the public IP address of Baselime's platform. Your OTEL collector then sends the telemetry data to Baselime's platform over the public internet. Our endpoints are protected by TLS, so your data is encrypted in transit. Sending data without PrivateLink"]},{"l":"With PrivateLink Endpoint","p":["When using Baselime with a PrivateLink endpoint, the DNS otel-ingest.baslime.io resolves the the private IP of a Network Interface that exists in your VPC, and the IP itself is one of from the CIDR range of your VPC. Your OTEL collector then sends the data to Baselime's platform over the private network. This means that your data never leaves AWS infrastructure, and is never exposed to the public internet.","Sending data with PrivateLink","Read more about AWS PrivateLink on the AWS website."]}],[{"l":"Render","p":["Render is a cloud platform for hosting and deploying web applications and websites. It provides a way to securely stream logs from your services deployed on Render to Baselime using the Syslog protocol over TLS."]},{"l":"Baselime integration","p":["Baselime provides advance logging capabilities for servoces deployed on Render. You can start streaming your logs from Render in a few steps:"]},{"l":"Step 1. Create an environment on Baselime","p":["Navigate to the Baselime console, create and environment and select \"Connect Render account\".","Once the environment is created, copy the BASELIME_API_KEY."]},{"l":"Step 2. Create the Log Stream in Render","p":["Navigate to your Render dashboard, select Log Streams, and Add Log Stream.","Log Streams"]},{"l":"Step 3. Configure the Log Stream","p":["Set Log Endpoint to syslog.baselime.io:514","Set Token to render:BASELIME_API_KEY","Add the Log Stream","Replace BASELIME_API_KEY with the API key from the Baselime console is Step 1.","Make sure to prefix the Token with render:. This enables Baselime to adequately parse logs from Render and enable you to run complex queries on them.","Add Log Stream"]},{"l":"Step 4. Use your logs from Render","p":["Once the Log Stream is created, all your logs from Render will be available in Baselime for searching, queries, dashboard and alerts. No further code changes are required in your code base."]}],[{"l":"Docker Logs","p":["Docker is an open platform for developing, shipping, and running applications and services.","You can stream your Docker container logs to Baselime over HTTPS by configuring a logging driver for each container. In this guide we'll show you how to configure the Fluentd and Fluent Bit logging drivers to stream your logs to Baselime.","The steps in this guide are implemented in this example project."]},{"l":"Driver configuration","p":["Fluentd and Fluent Bit allow you to specify sources (inputs) and sinks (outputs) and processors (filters) in a configuration file.","Below, you can find a configuration file for each of the drivers, which matches all inputs and sends them to Baselime.","FluentD listens on port 24224 by default, so no additional configuration is required.","FluentBit does not listen on any port by default, so you need to configure it to listen on port 24224 and forward the traffic. This way Docker can send the logs to Fluent Bit.","Make sure to replace BASELIME_API_KEY in configuration file with your Baselime API key from Baselime console.","You can send the logs to a different dataset by replacing logs in the URL https://events.baselime.io/v1/logs with a different dataset name."]},{"l":"Single container","p":["Step 1: Create the configuration file for your logging driver and replace BASELIME_API_KEY.","Step 2: Start your logging driver with configuration file mounted as a volume.","Step 3: Start your Docker container and specify a logging driver as with options--log-driver and --log-opt.","Baselime uses Docker labels io.baselime.service and io.baselime.namespace for service name and the namespace.","If your logging driver exists in a different network, or you've specified a different port, make sure to update the localhost:24224 accordingly.","Step 4: View your logs in the Baselime console."]},{"l":"Using Docker Compose","p":["If your containers are orchestrated using Docker Compose, you can stream logs from multiple containers to Baselime using the following docker-compose.yaml file."]},{"l":"Best practices","p":["To best utilise the advanced query capabilities of Baselime, we recommend sending logs in JSON format."]}],[{"i":"flyio","l":"Fly.io","p":["Fly.io is a platform for running applications globally. You can stream your Fly.io service logs to Baselime using the fly-log-shipper."]},{"l":"Setup","p":["Step 1: Get your BASELIME_API_KEY from the Baselime console.","Step 2: Create a Fly Log Shipper service and set the secrets using following commands:","Once these steps are completed, logs from all services deployed on Fly.io will be streamed to Baselime, and available for search, queries, alerts and dashboards.","Instrument fly.io tracing and metrics using OpenTelemetry"]}],[{"l":"Koyeb Logs","p":["Koyeb is a serverless platform that enables you to run applications without having to manage servers and infrastructure. You can stream your Koyeb services logs to Baselime using their log exporter.","Streaming logs from Koyeb to Baselime required a Koyeb API Key and a Koyeb Logger service."]},{"l":"Generate your Koyeb API Key","p":["Generate your Koyeb API Key in 4 steps:","Select the organisation you want to add logging to.","Navigate to \"Organization Settings\"","Select \"API\" from left-hand menu","Create new API key and copy it for later"]},{"l":"Create a logger service","p":["Add environment variables to the new app","Add the following environment variables:","app-name with the name of your Koyeb app","app-name/service-name","BASELIME_API_KEY","BASELIME_API_KEY with your public BASELIME_API_KEY","Create a Logger service in Koyeb. This service will stream logs from your Koyeb services in real-time to Baselime.","Create a new Docker App in Koyeb","Deploy the logger service.","Get your public BASELIME_API_KEY from the Baselime console","https://events.baselime.io/v1/koyeb","KOYEB_SERVICE","KOYEB_TOKEN","KOYEB_TOKEN with the Koyeb API Key generated in the first step","Once the service is deployed logs from your Koyeb application will be available to query in the Baselime console.","Replace","service-name with the name of the service within your Koyeb app you want to stream logs to Baselime.","Use the koyeb/log-exporter image with \"Tag\" v1.0.0-webhook","Variable Name","Variable Value","WEBHOOK_TOKEN","WEBHOOK_URI"]}],[{"l":"Vector","p":["Vector is a high-performance, open-source, observability data router. It can be configured to stream your logs to Baselime over HTTPS.","The steps in this guide are implemented in this example project."]},{"l":"Setup with Docker","p":["Step 1: Get your BASELIME_API_KEY from the Baselime console.","Step 2: Setup sources in the vector.yaml file following the Vector documentation.","Step 3: Add the Baselime sink to the vector.yaml configuration file:","Make sure to replace BASELIME_API_KEY with your Baselime API key from Step 1.","You can send the logs to a different dataset by replacing logs in the URL https://events.baselime.io/v1/logs with a different dataset name.","Step 4: Start the Vector container and mount the configuration file.","Once these steps are completed, logs from all containers mounted with Vector will be streamed to Baselime, and available for search, queries, alerts and dashboards."]},{"l":"Docker Labels","p":["Baselime uses Docker labels for service names. Add the relevant label to all your containers to ensure they are appropriately tagged.","io.baselime.service- used to extract service name used in Baselime console."]}],[{"l":"Kubernetes Logs","p":["If you use Docker or Podman as your container runtime, you can stream your container logs to Baselime by using Fluentbit DaemonSet as your logging driver"]},{"l":"How to configure","p":["First create a configuration yaml","Obtain your API key from the console Baselime console.","Next install the Baselime Helm chart"]},{"l":"Best practices","p":["We expect the log messages to be in JSON format. For example:"]},{"l":"How it works","p":["Sending Telemetry data to Baselime","DaemonSet provided above creates an instance of FluentBit pod on each node in your cluster. The FluentD pod reads the logs from the /var/log/containers/*.log and /var/log/pods/*.log directories and sends them to Baselime over HTTPS.","You can find example implementation in our GitHub repository"]}],[{"l":"Data Validation","p":["Baselime has a size limit for events of 256kb. This size limit helps ensure that the ingestion process is efficient and that the data stored in Baselime is manageable and fast to query. If an event exceeds this 256kb size limit, it will not be ingested into Baselime."]},{"l":"Sending Semi-Structured Logs to Baselime","p":["Semi-structured logs are logs that are not in the strict JSON format, but still contain structured data that can be extracted. These logs contain a mixture of structured and unstructured data, making them difficult to parse and analyze. Baselime has built-in mechanisms to parse and extract relevant data from semi-structured logs.","Baselime will automatically detect log events that contain JSON data, but are prepended or appended by a generic string.","The generic string will be wrapped in a message attribute, and the JSON data will be wrapped in a data attribute. This enables you to extract and analyze relevant data from semi-structured logs."]},{"l":"Examples","p":["Here are examples of automatic semi-structured logs detection."]}],[{"l":"Correlate Logs with Traces","p":["Baselime enables you to correlate your logs with your distributed traces. For platforms with direct deep integrations such as AWS Lambda or Vercel, this is done automatically.","If you send your logs and traces to Baselime manually, adding a traceId field to your logs will enable logs and traces correlation."]},{"l":"How it works","p":["To enable correlating your logs and traces, add the traceId to your logs.","If you use a custom logger, we recommend the traceId to all the logs by default.","There are a set of instrumentation packages for major logging libraries; for example:","Winston: @opentelemetry/instrumentation-winston","Pino: @opentelemetry/instrumentation-pino","Search your favourite package manager for the OpenTelemetry instrumentation of your favourite logger."]},{"l":"Usage","p":["Baselime will automatically correlate your logs and traces and you will be able to view the trace associated with a log, or from the trace, hop into the associated logs.","Logs/Trace correlation in Baselime"]}],[{"l":"Events API","p":["Baselime provides an Events API which enables you to send data to Baselime by making a POST request to the API endpoint. It enables you to send data directly from your applications or services to Baselime, rather than using a logging or monitoring service as an intermediary."]},{"l":"Request Format","p":["Each request ingests a batch of events into Baselime. Events are part of the request body. Baselime supports Content-Type application/json.","The request body must be an array of JSON objects. Any element of the array that cannot be parsed as valid JSON will be rejected.","Requests must be made to the /dataset route. dataset is the name of the dataset you want events to be stored in."]},{"l":"Authentication","p":["Add a public Baselime API key in the x-api-key header to all requests made to the Events API. You can get your API key from the Baselime console."]},{"l":"Request Headers","p":["Optionally, you can send the service and/or namespace properties in the request headers","Header","Value","x-service","The name of the service the events originates from","x-namespace","The name of the namespace the events originates from"]},{"l":"Validation","p":["The Events API validates the every request and returns a 400 Bad Request status code if any of the events fail validation. If some events pass validation and others fail, Baselime will ingest the events that pass validation. If you encounter a 400 Bad Request error when submitting events to the Events API, the events that failed validation will be listed in the body of the request under the invalid key."]},{"l":"Requirements","p":["Baselime accepts up to 6MB of uncompressed data per request","Each event must be a properly formatted JSON","Each event must be smaller than 256kb of uncompressed JSON"]},{"l":"API Response codes","p":["Baselime returns a 202 response for all valid requests to the Events API, and a range on of non- 200 responses for errors.","We welcome feedback on API responses and error messages. Reach out to us in our Slack community with any request or suggestion you may have."]},{"l":"Successful responses","p":["Status Code","Body","Meaning","202","{message: Request Accepted}","All the events were successfully queued for ingestion"]},{"l":"Failure responses","p":["Status Code","Body","Meaning","405","{message: Method Not Allowed}","The HTTP method is not allowed","401","{message: Unauthorised}","Missing or invalid API Key","400","{message: Bad Request}","- Missing or invalid path parameters ( v1 or dataset) - Unable to parse the request body as valid JSON- Empty request body - At least one of the events exceed the 256kb size limit - At least one of the events could not be parsed as valid JSON","500","{message: Internal Error}","An unexpected error occurred"]}],[{"l":"Enriching Logs in Baselime","p":["Baselime enables you to enrich your logs with special fields to enable deeper insights into your application's performance and traceability.","The available fields are:","requestId","duration","traceId","error","namespace","service","You can add those fields to your logs to enable the Requests view in Baselime.","Baselime automatically adds those fields to logs coming from cloud services with deep integrations such as AWS Lambda, Vercel and Cloudflare Workers."]},{"l":"Grouping your logs by request","p":["Baselime enables you to group your logs by request by adding a requestId field to all the logs and events within the same request.","In an Express.js server:","You can leverage your favourite logger to automatically add the requestId field to all the logs within a single request.","In addition to HTTP requests, you can use the requestId field to group logs for any task, such as background jobs or build processes."]},{"l":"Measuring Request Duration","p":["Add the duration field to at least one log or event from a request to measure its duration and enable analytics on request durations in Baselime.","For example, in an Express.js server:"]},{"l":"Capturing errors in your events","p":["Add the error field to any event where an error occured in your application. The value of the error field must be a string. Any event with the error field will be captured by the Baselime automatic error-tracking.","For example:"]},{"l":"Grouping logs by namespace or path","p":["Baselime enables you to group your logs by namespace or path by adding a namespace field to at least one log from a given request.","In an Express.js server:"]},{"l":"Grouping logs by service","p":["Baselime enables you to group your logs by service by adding a service field to all logs from the same service.","For example:"]},{"l":"Correlating logs and traces","p":["Refer to the Correlate Logs with Traces section."]},{"l":"Usage","p":["Once you have enriched your logs with the additional fields, your data will show in Baselime in the Requests view.","Enriched logs in Baselime"]}],[{"l":"Rehydrating telemetry data from Amazon S3","p":["This page describes how you can rehydrate your telemetry data from Amazon S3 into Baselime.","Once received, all telemetry data from your AWS Accounts is securely stored in hot storage for querying and in cold storage within your own AWS environment, in an Amazon S3 bucket in your AWS account. This ensures that you have complete long-term control over your data and its storage location.","Sending Telemetry data to Baselime","The retention period of your telemetry data on Baselime is independent of the retention periods in AWS. You can safely reduce the retention period of your CloudWatch log groups."]},{"l":"How it works","p":["When your data is streamed to Baselime, through different sources described in the Sending Data to Baselime section, it is also streamed to a Kinesis Firehose created in your AWS account. The Data Firehose stores the telemetry data in a S3 bucket in your AWS account.","This gives you full ownership of your data and enables you to use it outside the Baselime; for example to feed it into a data lake. It is also possible to rehydrate the data from the S3 bucket into Baselime once the data is past its expiration period on Baselime.","Data flow","We set the default TTL for objects stored in the bucket to 180 days to prevent extremely long storage of telemetry data you might not need; Feel free to adjust it to your needs."]},{"l":"How to use it","p":["First, you'll need to have Baselime CLI installed. You can find the installation instructions here.","Once you have it installed, you can use the following command to rehydrate your data:","Start date should be formatted in RFC3339 format, and hours to recover should be a number. The process will recover all the data from the start date, for the number of consecutive hours from that date."]}],[{"l":"Sampling","p":["Sampling enables you to control the volume of data processed and ingested in Baselime, by selecting only a portion of your data, whilst keeping the ability to extrapolate key insights from the selected set."]},{"i":"when-should-you-consider-sampling","l":"When should you consider sampling?","p":["You should consider sampling when your data volumes are high, when you exceed multiple billion events per day, or multiple thousand requests per second.","Sampling will enable you to reduce the overall volume of data processed and stored, and keep only data where \"interesting things\" occur. Interesting things could be errors, events with specific attributes, or events with high latencies associated."]},{"l":"Automatic tail sampling with Baselime","p":["Automatic tail sampling is available only on our Enterprise Tier","You can enable automatic tail sampling on Baselime for each of your datasets.","With tail sampling, the decision to sample a trace or request happens at the end of the processing, by considering all of the spans and events within the trace or request. A trace/request is sampled (ingested) when:","At least one event has an error (for logs, log levels are considered)","At least one event has a status code > 399","it meets the deterministic probability sampling, based on a fixed sampling rate","If any event (logs, spans and span events) associated with a trace or request meets the criteria, the entire trace or request is sampled. Otherwise, it is dropped.","If your events are not associated to any trace or request, they are sampled using the same criteria, but are kept individually instead of as part of a request.","Learn how to enrich your logs with request IDs for faster troubleshooting."]},{"l":"How Baselime works with sampled data","p":["When Baselime automatically samples your data, it also saves a $baselime.samplingInterval on each of your events. If you decide to sample with a N sampling rate, Baselime will automatically store 1/N as the $baselime.samplingInterval.","Baselime then uses the sampling interval to compute aggregations such as COUNT, SUM, AVG and all percentiles.","In other words, Baselime enables you to perfrom accurate calculations that are representative of the entire dataset, even with a sampled dataset.","Baselime also surfaces the average sample rate in the query results in the console. This gives you an idea of the sample rate of the events queried when running a query."]},{"l":"COUNT_DISTINCT","p":["COUNT_DISTINCT enables you to compute the number of unique values a property take in your dataset. This is impossible to accurately compute with sampled data. When performing a COUNT_DISTINCT aggregation, Baselime will count the number of unique values present in the sampled dataset and will not compensate for the sampling rate."]}],[{"l":"Troubleshooting in Baselime","p":["Baselime enables you to troubleshoot your systems and find issues faster. You can search, slice and dice your data against any dimension to get answers to your questions."]},{"l":"Search","p":["Once you've created an environment in Baselime and sent data (logs, metrics, traces or wide events), you can search for any string or regular expression in your data.","Click on your environment","Click on one of the discovered services (or the default service)","Enter your search expression","Baselime will surface all the requests where the search expression is found. This search is performed on logs, spans, span events and wide events.","Search in Baselime","Expand each request to view the logs and the trace of the specific request."]},{"l":"Filter","p":["From any screen on Baselime with telemetry data, you can filter the data by any of the fields persent in the data.","Baselime supports high cardinality and high dimensionality. This means you can send data with as many nested fields as you want, and those fields can have as many possible values as you want. For example, in your logs or traces, you can send a requestId to Baselime, which can have millions of unique values; and you will be able to filter by any of these values.","Filter in Baselime"]},{"l":"View requests and traces","p":["Once you've searched an/or applied filters to your telemetry data, you can drill down into a single request or trace, view all the logs, spans and span events related to the request.","Request logs in Baselime Trace map in Baselime Trace timeline in Baselime"]},{"l":"Compute aggregates","p":["Add a filter $baselime.error EXISTS","Add a group by @message or @message.message","Add a order by","add a search expression","Add a visualisation COUNT","add more visualisations, filters, and group bys","Baselime has an internal tab system. Start a new tab by clicking on the + at the top of the screen, select Start new query and Start from scratch.","Baselime query builder","Click Run query","Sometimes you want to troubleshoot an issue that impacts more than one user. For example, you might want to count the number of requests that returned an error status code and group them by route, or you might want to compute the latency of your requests.","The Baselime query builder is the most powerful way to explore your data in Baselime. It gives your the tools to keep drilling down and surface insights from your telemetry data.","This is where the Baselime query builder shines.","view the raw data (the list of events) that match the filters","view the requests and traces associated with these events","You'll see a count of all the events where there was an error, grouped by the error message. You can zoom:","zoom in on the chart"]}],[{"l":"Real-Time Error Tracking in Baselime","p":["Baselime automatically tracks all errors occuring in your applications and notifies you with those that need your attention in real-time."]},{"l":"Errors","p":["The Errors page displays errors in your applications, across your services. You can filter errors by service or search using case-sensitive search.","When you connect your cloud account to Baselime, your applications send logs, metrics, traces and wide events to Baselime. On each event, Baselime determines if it's an error. This is typically determined by:","The log level: anything above error or critical log level","The status of the span: every span with an error (from both OpenTelemetry and AWS X-Ray)","If the event has a root level property level set to error or critical.","Baselime then computes the fingerpring of the error. The fingerprit is based on multiple variables:","dataset","service","namespace","account","region","level","errorString","Errors are uniquely represented by their fingerprint. Errors with a different set of the variables above are distinct errors. If a similar error with the same fingerpring occurs, you will not get notified, the occurences counter will increase instead.","The occurences counter is refreshed after 30 days since the first occurence of the error. If the error is not resolved or ignored within 30 days and occurs once more, you'll be notified."]},{"l":"Error status","p":["Errors can have a status in Baselime:","Active","Ignored","Resolved","You can change the status of any error from the Baselime console. The status reflects the behaviour of the error fingerprint when the same error is occurs again in your architecture."]},{"l":"Active errors","p":["This is the default status of all errors when they are detected. When an error in Active state occurs, you will get notified only the first time it happens. You will not not get notified again until the fingerprint expires 30 days after the first occurence of the error. As such, if the error is not resolved within 30 days and it occurs again, you will get notified."]},{"l":"Ignored errors","p":["When an error in Ignored state occurs, you will not get notified ever. This is useful for expected errors, where they occur in your applications, but no action is required."]},{"l":"Resolved errors","p":["When an error is marked as Resolved, you will get notified the first time it happens again, and it will be automatically marked as Active. This is helpful for when you have resolved an error in your applications, but it happens again for a set of edge-cases. You will know about it as soon as it happens again."]},{"l":"Merging Errors","p":["Baselime enables merging similar errors that have not automatically been grouped together. In the Baselime console you can merge multiple errors into a single one. Merged errors are not shown in the main list of errors and are available from within the error they are merged into."]},{"l":"Deleting Errors","p":["You can delete errors. When you delete an error, all its history is lost, and this action is irreversible. If the same error occurs again in the future, we will create a new Error for it and notify you as per your notification settings."]},{"l":"Assigning Errors","p":["You can assign an error to any of your member of your team to facilitate error triage."]},{"l":"Error details","p":["The error details page gives you an overview of the error and enables you to dig deeper into the data and understand why the error occured.","It displays the first and last time the error was seen in your telemetry datam the number of occurences in the past 30 days, the cloud account the error originates from, and the dataset. From this screen it is also possible to directly change the status of an error or assign it to a member of your team.","For each error, the errors details screen also displays:","A sample request","A sample trace","A sample error event","The 30-day History of occurences","From this screen you can click on the Investigate button to hop into the query builder to dig deeper in the issues."]}],[{"l":"Service Home","p":["Every service in Baselime has a service home. The service home is where you get both a high-level overview of your service as well as the ability to drill down and investigate issues quickly."]},{"l":"Requests","p":["The requests view displays a summary of your requests and the list of the requests within the selected timeframe in chronological order."]},{"l":"Summary","p":["The summary includes three charts:","Number of events: the total number of events your service emitted","Errors: the total number of errors in your telemetry data","Request latencies the 90th percentile latencies of requests and traces","You can drill down on any of these charts by clicking on the chart. It opens the Baselime query builder where you can slice and dice your data further."]},{"l":"List of requests","p":["Below the summary charts, there is a search bar, a filter button and the list of requests.","You can search for any string or regular expression using the search bar. Baselime will search through all the events (logs, spans, span events and wide events) from your service and display the requests where at least one event matches the search criteria.","You can filter by any high-dimensionality field in your data using the filter button. Baselime fill filter through all the events (logs, spans, span events and wide events) from your service and display the requests where at least one event matches the applied filters.","If you add simultaneously a search criteria and filters, Baselime will find events that matches all searches and filters and displat the corresponding requests.","You can expand each request and view the logs and the trace of the request. Also, to facilitace filtering, it's possible to filter directly from the logs or the trace of a request. Use the option menu at the end of each line in the events JSON.","The menu inside the JSON event is available across Baselime, wherever an event is displayed. This enables you to quickly go from an event to investigating further, without loosing the context of the event."]},{"l":"Events","p":["The events view displays all the events captured your service during the selected timeframe. The events comprise all logs, spans, span events, wide-events and metrics sent to Baselime.","You can search for events and filter events from this view. You can zoom in on the bar chart of the event volume."]},{"l":"Traces","p":["The traces view displays the traces captured from your service within the selected timeframe. It includes a trace scatter plot, where the y-axis is the duration of the traces and the x-axis is the timestamp. In addition to the scatter plot, the trace view displays a list of traces from your service in chronological order.","You can search and filter traces using the search bar and the filter button.","The scatter plot is color-coded:","Red: traces with at least one span with an error","Green: succesful traces","Blue: Traces where there is a cold-start (for serverless functions)","You can click on any of the dots in the scatter plot to display the trace.","You can also click on any of the traces in the list to display the complete trace.","Once you're viewing a trace, you can click on any of the spans to view the the span the logs of the traces, the span events, and the span details."]}],[{"l":"Automatic Service Discovery","p":["Baselime automatically discovers services in your cloud accounts and organises your observability data following services and teams boundaries. This enables you to quickly sift through the vast amounts of data your applications produce."]},{"l":"Discovering Services","p":["Baselime automatically discovers all cloud resources in your cloud accounts. Each resource is linked to a service. The service is typically based on the deployment framework that you use.","The service name is the name of the CloudFormation template the AWS CDK generates during cdk synth","The name of the service is the name of the SST app","The name of the service is the name of the Serverless Framework App","The name of the service is the name of the CloudFormation template generated when deploying the AWS SAM application","The name of the service is the name of the CloudFormation template","When ingesting data from your architecture, Baselime correlates the incoming data with the service name of the cloud resource the data originates from."]},{"l":"Overriding the service discovery on AWS","p":["To force the resources from a CloudFormation stack to belong to a service with a different name, set the value of the tag baselime:service to the desired service name on the CloudFormation template. All resources deployed with the CloudFormation template will be correlated with the desired service name."]}],[{"l":"Queries","p":["Queries are the building blocks of all interactions with your telemetry data on Baselime. When you view a request or a trace, it's the result of a query.","You can run queries both in the Baselime console and using the Baselime CLI."]},{"l":"Queries in the Console","p":["From anywhere in the Baselime console you can start a new query by clicking on the \"New query\" button.","You can use the query builder to construct queries to explore your data, investigate issues and resolve performace bottlenecks. The query builder is aware of your observability data and will recommend values such that you always query within the context of your data.","Sending AWS App Runner logs to Baselime"]},{"l":"Queries in the CLI","p":["You can also run queries using the Baselime CLI. To do so, use the baselime query command.","Use the baselime query without any flags to enter interactive mode where you can specify all the arguments of your query interactively.","You can also run saved queries using the CLI, either in interactive mode or by passing the arguments as flags","You can also save your query results to a file. Use the --format to print the results of the query in JSON, and pipe them to a file.","For more advanced usage of the baselime query command, please refer to the CLI reference."]}],[{"l":"Alerts","p":["Baselime's alerting feature enables you to set up notifications for when certain conditions are met in your telemetry data. This can be helpful for detecting and responding to issues in your system in real-time."]},{"l":"Setting up alerts","p":["To set up an alert, you will need to specify a query and a threshold. When the result of the query meets the conditions the threshold, the alert will be triggered. You must also specify the frequency to check the query, and time window to consider for the alert.","You can set up alerts using the Baselime CLI with Observability as Code using the Observability Reference Language or the web console. Here is an example of how to set up an alert with ORL:","To create this alert, add it to a any .yml file in your .baselime folder. If you don't have a .baselime folder for your service, create it with baselime init.","Once you have the .baselime folder configured, run the following command to create your alert:"]},{"l":"Receiving alerts","p":["When an alert is triggered, you can choose to receive notifications through a variety of channels, such as email, Slack or webhook."]},{"l":"Tips for effective alerting","p":["Make sure to set appropriate thresholds for your alerts. Setting the threshold too low may result in false positives, while setting it too high may result in missed issues.","Keep alerts specific and actionable: Alerts should be specific and provide clear instructions on what action to take.","Set up alerts for the right things: Make sure to set up alerts for the most important issues that need immediate attention.","Use multiple alerting methods: Use a combination of Slack, email, and webhooks to ensure that you are notified of important issues in a timely manner.","Use alert suppression: Silence repeated alerts to avoid alert fatigue and ensure that you are only notified of important issues.","Consider using webhook alerts to build self-healing systems","Test your alerts to ensure they are working as expected.","Use alert analytics: Use alert analytics to analyze the effectiveness of your alerting strategy and make improvements where necessary.","Regularly review and update alert thresholds and configurations to ensure they are still relevant and effective."]}],[{"l":"Tailing your data","p":["The baselime tail command enables you to stream telemetry data in real time to your terminal. This can be useful for debugging or quickly checking the status of your services.","By default, the baselime tail command will stream all telemetry data for your Baselime environment. You can further filter the data by adding query parameters, such as:","This will only show the events where data.user.id is 123456 and the word error appears in the event.","You can also specify a time range for the data being streamed:","Alternatively, you can define the timerange in relative format","This will stream telemetry data between the specified start and end times.","The baselime tail command can be a useful tool for quickly checking the status of your application and identifying any issues that may be occurring."]}],[{"l":"Reports","p":["Baselime reports are a powerful tool that enable you to compare the state of a service before and after making changes. By incorporating Baselime reports into your CI/CD pipeline, you can see the impact of changes in production. This improves the reliability of your deployments and enables you to build self-healing systems.","For example, if a report after deployment fails, you can roll back or roll forward to ensure the stability of your service.","Here is an example of how you can use the baselime report command in a GitHub Action to compare the state of a service before and after a deployment:","This workflow takes a snapshot with baselime report github before and after running the deployment script ( npm run deploy). The reports are posted on the commit that triggered the workflow. By comparing the two snapshots, you can see how the deployment affected your service and take appropriate action."]},{"l":"Running a report","p":["To run a report, use the baselime report command. By default, this will create a snapshot of all the alerts in the current service, display the results in the terminal, and save them to a file.","To publish a report to GitHub, run:"]}],[{"l":"Tux","p":["Tux is an AI assistant that resolves errors and performance issues in your applications. Tux understands your architecture by leveraging the powers of Baselime to gather context from your telemtry data, and enables you to resolve issues before they become problems.","Tux is your personal observability assistant, equiped with a deep understanding of:","Your telemetry data (logs, metrics, traces, wide events, etc.)","Your cloud architecture","Vast knowledge of open-source code"]},{"l":"Getting started","p":["You can start using Tux as soon as you start sending data to Baselime."]},{"i":"what-data-is-collected-and-how-is-it-used","l":"What data is collected and how is it used?","p":["Tux collects and uses data in the following ways:","Prompts and responses: When you use Tux, Baselime collects your prompts and responses to provide the service. Baselime does not use any of our data to train models.","Usage data and feedback: Baselime collects usage data and feedback to improve the developer experience."]}],[{"l":"Tux Quickstart","p":["Tux offers an interactive, chat-based interface that enables you ask questions about the behaviour of your applications."]},{"l":"Key Features","p":["You can start a chat with Tux from one of:","A trace","A request","An error","by clicking on the \"Analysis\" tab.","Analysis tav","Tux starts analysing your data within the context you requested it. For example, if you ask for analysis of a trace, Tux will request the trace from Baselime, alongside the associated logs and span events, and also the known shape of your application architecture.","Example trace Example analysis from Tux","Tux will use this data to give you comprehensive insights into the behaviour of your application, with actionable suggestions and code samples for fixing issues fast.","From there you can ask subsequent questions to delve deeper into the analysis. Tux can run complex queries on your telemetry data and correlate with your application architecture.","Subsequent question with a query"]},{"l":"Example of Use","p":["Error Analysis: Submit an error and ask Tux to identify the root cause. Follow up with questions about potential fixes.","Performance Optimization: Analyze a trace to understand performance bottlenecks and receive optimization suggestions."]}],[{"l":"Tux FAQ"},{"l":"General"},{"i":"does-tux-train-on-my-telemetry-data","l":"Does Tux train on my telemetry data?","p":["No, Tux does not train on your telemetry data. Our third-party Language Model (LLM) providers also do not train on your specific data. Tux operates by following a specific process to generate answers to your queries:","User query: A user asks a question","Code retrieval: Baselime, performs a query to retrieve the relevant telemetry data to the user's question. During this process, strict permissions are enforced to ensure that only telemetry data for the user is retrieved","Prompt to Language Model: Baselime sends a prompt, and the telemetry data to a Language Model (LLM). This prompt provides the context for the LLM to generate a meaningful response","Response to user: The response generated by the LLM is then sent back to Tux and presented to the user","This process ensures that Tux can provide helpful answers to your questions while respecting data privacy and security by not training on or retaining your specific telemetry data."]},{"i":"is-there-a-public-facing-tux-api","l":"Is there a public facing Tux API?","p":["Currently, there is no public-facing Tux API available."]},{"i":"does-tux-require-baselime-to-function","l":"Does Tux require Baselime to function?","p":["Yes, Tux relies on Baselime for two essential functions:","It is used to retrieve context relevant to user queries","Baselime acts as a proxy for the LLM provider to facilitate the interaction between Tux and the LLM"]},{"i":"can-tux-answer-questions-non-related-to-observability","l":"Can Tux answer questions non-related to observability?","p":["Tux is an expert in cloud computing and observability. Tux is not designed to answer non-observability related questions or provide general information on topics outside of cloud computing or your applications."]},{"l":"Third party dependencies"},{"i":"what-third-party-cloud-services-does-tux-depend-on","l":"What third-party cloud services does Tux depend on?","p":["Tux relies on one primary third-party dependency, i.e., OpenAI API."]},{"i":"can-i-use-my-own-api-keys","l":"Can I use my own API keys?","p":["No, you cannot use your own API keys at this point."]}],[{"l":"Installing the Baselime CLI","p":["The Baselime CLI enables you to interact with Baselime and your observability data through the command line."]},{"l":"Installing","p":["Installing with Homebrew","Installing with curl","Installing with npm","Optionally, you can download the latest version of the Baselime CLI binary from the releases page on GitHub.","Download the binary for your operating system and architecture (e.g., baselime_linux_x64 or baselime_darwin_x64).","Unzip the tarball with tar -xf baselime-os-arch-version.tar.gz","Make the binary executable with chmod +x baselime.","Move the binary to a directory in your PATH, such as /usr/local/bin, with mv baselime /usr/local/bin/baselime.","On some systems, you might need to run these commands with sudo."]},{"l":"Verifying the installation","p":["Verify that the Baselime CLI was installed with:"]},{"l":"Authenticating the CLI","p":["Before you can use the Baselime CLI, you must authenticate it with your Baselime account.","To use the Baselime CLI in non-interactive evironments, such as in CI pipelines, set the BASELIME_API_KEY environment variable to your Baselime API key and the CLI will use it for all commands."]},{"l":"Updating the Baselime CLI","p":["To update the Baselime CLI to the latest version, use one of the following commands depending on how you originally installed it:","If you installed with brew, run brew upgrade @baselime/cli","If you installed with curl, run baselime upgrade","If you installed with npm, run npm update -g @baselime/cli"]}],[{"l":"Anonymous Telemetry","p":["Baselime collects completely anonymous telemetry data about general CLI usage. Participation in this anonymous program is optional, and you can opt-out if you'd not like to share any information."]},{"i":"how-do-i-opt-out","l":"How do I opt-out?","p":["You can opt out-by running the following command:","You can re-enable telemetry if you'd like to rejoin the program by running."]},{"i":"why-do-we-collect-telemetry-data","l":"Why do we collect telemetry data?","p":["Telemetry data help up to accurately measure the Baselime CLI feature usage, pain points, and customisation across all developers. This data empowers us to build a better product for more developers.","It also allows us to verify if the improvements we make to the Baselime CLI are having a positive impact on the developer experience."]},{"i":"what-is-being-collected","l":"What is being collected?","p":["We measure the following anonymously:","Command invoked (ie. baselime deploy, baselime query, or baselime tail)","Version of Baselime in use","General machine information (e.g. number of CPUs, macOS/Windows/Linux, whether or not the command was run within CI)","An example telemetry event looks like:","These events are then sent to an endpoint hosted on our side."]},{"i":"what-about-sensitive-data-or-secrets","l":"What about sensitive data or secrets?","p":["We do not collect any metrics which may contain sensitive data.","This includes, but is not limited to: environment variables, file paths, contents of files, logs, or serialized errors."]},{"i":"will-the-telemetry-data-be-shared","l":"Will the telemetry data be shared?","p":["The data we collect is completely anonymous, not traceable to the source, and only meaningful in aggregate form.","No data we collect is personally identifiable.","In the future, we plan to share relevant data with the community through public dashboards or reports."]}],[{"l":"baselime console","p":["Use the baselime console command to open the Baselime console."]}],[{"l":"baselime iam","p":["Use the baselime iam command to display the currently logged-in user and environment."]}],[{"l":"baselime login","p":["Use the baselime login command to log in your Baselime account and select an environment."]}],[{"l":"baselime logout","p":["Use the baselime logout command to log out of Baselime."]}],[{"l":"baselime mark","p":["Use the baselime mark command to create a marker."]}],[{"l":"baselime query","p":["Use the baselime query command to run a query on your telemetry data data."]}],[{"l":"baselime rehydrate","p":["Use the baselime rehydrate to rehydrate Baselime hot storage with data from your Amazon S3 Bucket."]}],[{"l":"baselime report","p":["Use the baselime report command to generate a report based on your observability data and assess the health and performance of your service."]}],[{"l":"baselime tail","p":["Use the baselime tail command to stream events from your telemetry data in real-time."]}],[{"l":"baselime telemetry","p":["Use the baselime telemetry command to manage the usage telemetry data collected by the Baselime CLI."]}],[{"l":"baselime test","p":["Use the baselime test command to check all the alerts in your current service, display the results in the terminal, and output them to a file."]}],[{"l":"baselime upgrade","p":["Use the baselime upgrade command to upgrade the Baselime CLI to the latest version. This method will work only if you installed the Baselime CLI with curl -s https://get.baselime.io | bash."]}],[{"l":"Baselime CDK Quick Start","p":["Observability is a first class citizen of your infrastructure with Baselime. You can use the AWS CDK to define and automate your observability configurations in Baselime."]},{"l":"Installation","p":["Download the Baselime CDK on npm:@baselime/cdk"]},{"l":"Configuration","p":["Initialise the Baselime CDK with your Baselime API Key.","Get your API Key from the Baselime console. Make sure to select an Admin API Key. Admin API keys have the permissions to create resources in your Baselime account."]},{"l":"Example alert","p":["Set up an alert everytime there's an error in your application logs:","This alert will notify you on Slack when there is an event with LogLevel equal ERROR in your telemetry data."]}],[{"l":"Baselime CDK Queries","p":["Queries are used to retrieve and analyze data from various datasets in order to gain insights from your services."]},{"l":"Query Specification","p":["Heres a sample query in Baselime CDK that uses all of the supported settings for defining queries in Baselime. Use it to get started creating your own queries."]},{"l":"properties","p":["Queries have a set of properties that define the query's characteristics and behavior."]},{"i":"description-optional","l":"description (optional)","p":["The description of the query is a string that provides more information about the query. It can include details about the data being queried, the calculations being performed, and any other relevant information.","Example:"]},{"l":"parameters","p":["The parameters of a query define the datasets to query, the calculations to perform on the data, and any filters or groupings to apply."]},{"i":"datasets-optional","l":"datasets (optional)","p":["The datasets parameter is an array of strings that specify the names of the datasets to query. Baselime supports querying multiple datasets simultaneously, allowing you to analyze data from different sources in a single query. If no datasets are provided, Baselime CDK defaults to lambda-logs.","Example:"]},{"i":"filters-optional","l":"filters (optional)","p":["eq: Equals","Example:","exists: Exists (applies to fields that may or may not exist in the data)","Filters can be used to narrow down the data being analyzed and focus on specific events or attributes.","gt: Greater than","gte: Greater than or equal to","inArray: In (applies to arrays only)","includes: Includes","lt: Less than","lte: Less than or equal to","Moreover, it is possible to add a filter to a query after the query has been initialised.","neq: Does not equal","notExists: Does not exist (applies to fields that may or may not exist in the data)","notInArray: Not in (applies to arrays only)","notIncludes: Does not include","regex: Matches a regular expression","startsWith: Starts with (applies to strings only)","The filters parameter is an array of strings that specify conditions to filter the data by. Baselime CDK provides multiple helper functions to create query filters:"]},{"i":"calculations-optional","l":"calculations (optional)","p":["The calculations parameter is an array of strings that specify the calculations to perform on the data. Baselime CDK provides multiple helper functions to create query calculations:","count: Counts the number of events.","countDistinct: Counts the number of distinct occurences of a field (applies to strings only).","max: returns the maximum value of a field.","min: returns the minimum value of a field.","sum: returns the sum of all values of a field.","avg: returns the average of all values of a field.","median: returns the median of all values of a field.","stdDev: returns the sample standard deviation of a field.","variance: returns the sample variance of a field.","p001, p01, p05, p10, p25, p75, p90, p95, p99, p999: return the specified percentile of all values of a field.","Calculations can be used to perform statistical analysis on the data and derive insights such as the average request duration, the maximum response size, or the 95th percentile of request latencies.","It is possible to pass an optional alias to each of these functions, such that the results are displayed in the Baselime console or CLI using the alias.","Example:"]},{"i":"groupby-optional","l":"groupBy (optional)","p":["The groupBy parameter is an object that specifies how to segment the data by a field. It has the following fields:","value: The field to group the data by","limit: The maximum number of results to return (default: 10)","type: The type of the data field to group by (string, boolean, or number)","orderBy: The calculation to order the results by (default: the first calculation in the query)","order: The order in which to return the results (ASC or DESC, default: DESC)","Grouping the data by a field allows you to segment the results into distinct groups and analyze them separately.","Example:"]},{"i":"needle-optional","l":"needle (optional)","p":["The needle parameter is an object that specifies a search to perform on the data. It has the following fields:","value: The string to search for","matchCase: A boolean indicating whether the search should be case-sensitive(default: false)","isRegex: A boolean indicating whether the search value is a regular expression (default: false)","The needle can be used to find specific set of events or patterns in the data.","Example:"]},{"l":"Adding an alert","p":["Baselime CDK enables you to add an alert to a query. The alert will run the query on a defined schedule and notify you on your preferred channels when specific conditions are met."]},{"l":"Example Queries","p":["Here are example Baselime CDK queries that combine all of the above properties.","This query retrieves data from the otel traces dataset and performs several calculations on the data. It computes the average request duration, maximum response size, and 95th percentile of request latencies for each user ID in the dataset.","It filters the data to only include user IDs with a request duration greater than 500ms, and limits the results to the top 100 user IDs based on the average request duration. The results are ordered by the average request duration in descending order. The query also searches for the word \"error\" in the data and filters the results based on whether or not the word is present.","This Baselime CDK query calculates the total consumed read capacity units for each DynamoDB table in a service. It filters the data to only include events with a metric_name of ConsumedReadCapacityUnits and a unit of Count, and groups the results by TableName. The query returns the top 10 tables with the highest consumed read capacity units."]}],[{"l":"Baselime CDK Alerts","p":["Alerts are used to run a query on a schedule and notify you if a threshold is crossed. Baselime alerts are based on Baselime queries, which gives you you the flexibility to specify alerts on defects or events of interest, and reduce false positives and alert fatigue."]},{"l":"Alert Specification","p":["Heres a sample alert in Baselime CDK that uses all of the supported settings for defining alert in Baselime. Use it to get started creating your own alert."]},{"l":"properties"},{"i":"description-optional","l":"description (optional)","p":["The description of the alert is a string that provides more information about the alert. It can include details about the conditions being monitored and any other relevant information.","Example:"]},{"i":"enabled-optional","l":"enabled (optional)","p":["The enabled property is a boolean that indicates whether the alert is enabled or disabled. If set to true, the alert will be active and trigger notifications when thresholds are met. If set to false, the alert will be inactive and no notifications will be sent.","Example:"]},{"l":"parameters","p":["The parameters of an alert define the query to run, the threshold to evaluate, and the frequency and window for monitoring. query"]},{"l":"query","p":["The query parameter specifies the query to run for monitoring. It can reference an existing query object or include an inline query definition.","Example:","With the inline query the calculation defaults to [calc.count()]","or"]},{"l":"threshold","p":["The threshold parameter specifies the condition to evaluate from the query results. It can use helper functions to create comparisons or calculations, such as gt, lt, eq, count, etc.","Example:"]},{"l":"frequency","p":["The frequency parameter specifies the frequency at which the alert should run the query and evaluate the threshold. It uses a string representation of the frequency, such as '5 mins', '1 hour', '1 day', etc.","Example:"]},{"l":"window","p":["The window parameter specifies the time window to look back for data when evaluating the threshold. It uses a string representation of the time window, such as '10 mins', '1 hour', '1 day', etc.","Example:"]},{"l":"channels","p":["The channels property specifies the destinations to send the alert notifications. It is an array of channel objects, where each object defines the channel type and targets."]},{"l":"type","p":["The type property specifies the type of channel for the alert. Baselime CDK supports various channel types, such as 'email', 'slack', 'webhook', etc."]},{"l":"targets","p":["The targets property specifies the target destinations for the alert notifications. The targets can be specific emails, channels, or URLs depending on the channel type.","Example:","Moreover, you can define a defaultChannel when initialising your Baselime CDK, this channel will be used for all alerts in the service, simplifying your CDK code."]}],[{"l":"Baselime CDK Dashboards","p":["Dashboards give you a birds eye view of a collection of your query results. This can help you look at multiple related graphs on a single page to spot interesting trends.","Dashboards are a collection of queries and charts that you want to keep for future reference. Boards help you visualise multiple queries at once, to spot interesting trends and share your findings with your team."]},{"l":"Dashboard Specification","p":["Heres a sample dashboard in Baselime CDK that uses all of the supported settings for defining dashboard in Baselime. Use it to get started creating your own dashboard."]},{"l":"properties"},{"i":"description-optional","l":"description (optional)","p":["The description of the dashboard is a string that provides more information about the dashboard. It can include high-level details or any other relevant information.","Example:"]},{"l":"parameters","p":["The parameters of a dashboard define the widgets to display on the dashboard."]},{"l":"widgets","p":["The widgets parameter is an array of widget objects that specify the queries to run and the names of the widgets to display on the dashboard. name and description are both optional parameters for a widget.","Example:"]}],[{"l":"Baselime Terraform Provider","p":["Observability is a first class citizen of your infrastructure with Baselime. You can use Terraform to define and automate your observability configurations in Baselime."]},{"l":"Configuration","p":["Use the Baselime Terraform Provider to create and manage your observability resources on Baselime with Terraform.","Get your API Key from the Baselime console. Make sure to select an Admin API Key. Admin API keys have the permissions to create resources in your Baselime account."]},{"l":"Resource types","p":["Query","Dashboard","Alert"]},{"l":"Examples","p":["View examples in the Baselime Terraform Provider GitHub repository."]}],[{"l":"Data Security","p":["Baselime is committed to ensuring the security and privacy of our users' data. We have implemented a number of measures to ensure that data is encrypted in transit and at rest, and that it is not accessible from the public internet. Here are some of the key data security features of Baselime:"]},{"l":"Data Encryption","p":["All data transferred to and from Baselime is encrypted in transit using industry-standard protocols such as HTTPS and TLS. In addition, all data is encrypted at rest."]},{"l":"Private VPCs and IAM Roles","p":["Baselime runs in private Virtual Private Clouds (VPCs) and utilizes IAM roles to ensure that data is only accessed by authorized users and processes."]},{"l":"No Public Access","p":["Baselime does not expose any data to the public internet. All data is accessed via secure, authenticated channels."]},{"l":"Modern Best Practices","p":["Baselime follows modern best practices for data security, including regularly updating and patching our systems, implementing network segmentation and access controls, and conducting regular security audits and penetration testing."]},{"l":"Data Scrubbing and Obfuscation","p":["Baselime provides tools for scrubbing and obfuscating sensitive data, such as passwords, secrets, and API keys. Users can block or obfuscate specific keys by dataset using the .baselimeignore file. In addition, Baselime automatically scrubs a predefined list of sensitive fields, including \"password\" and \"secret\".","To learn more about how to use these features to protect your data, see the Baselime Telemetry Data Privacy documentation."]},{"l":"Compliance","p":["We're currently working towards compliance with a number of industry-standard security and privacy frameworks, including GDPR, SOC2 and HIPAA. Please contact us for more information on our compliance status."]},{"l":"Support","p":["If you have any questions or concerns about the security of your data in Baselime, please don't hesitate to contact our support team. We are always here to help!"]}],[{"l":"Telemetry Data Privacy","p":["Baselime is designed to help you observe the health and performance of your applications, and part of that involves collecting telemetry data. To ensure the privacy of your data, Baselime provides a number of features that enable you to control which data is collected and how it is used."]},{"l":"Obfuscating Keys","p":["Baselime enables you to obfuscate keys from being ingested into your datasets. This is particularly useful for sensitive information such as passwords, API keys, and other personal data. You can obfuscate keys for a specific dataset in the Baselime console, in the datasets section.","Keep in mind that obfuscating keys is a one-way process, meaning that once a key has been obfuscated, there is no way to recover the original value. Make sure to carefully consider which keys you want to obfuscate."]},{"l":"Automatic scrubbing","p":["access_token","Any nested field in your telemetry data that contains any of these automatically scrubbed keys will be blocked from ingestion by default.","api_key","apikey","auth","authorization","authorizer","Baselime that automatically obfuscate sensitive information from being ingested into the telemetry data by default. This is done to ensure that sensitive data is not accidentally exposed.","clientip","credentials","creds","passwd","password","pwd","refresh_token","refresh-token","secret","sourceip","The following keys are automatically scrubbed:","To turn automatic scrubbing on or off for a specific dataset, use the Baselime console, in the datasets section.","x-api-key"]}],[{"l":"Connectors","p":["Baselime uses connctors to automatically ingest telemetry data from your cloud environments."]}],[{"l":"AWS Connector on Baselime","p":["The AWS Connector allows you to send data from your AWS resources to Baselime. This includes logs, traces, and metrics. By connecting your AWS account to Baselime, you can get a unified view of your architecture, query your data, and set up alerts."]},{"l":"Setting up the AWS Connector","p":["The connector is an automated flow based on a CloudFormation template.","Navigate to the Baselime web console and login.","Follow the steps on the home screen to connect a new AWS Account. Baselime will generate a CloudFormation template for you to deploy on your AWS account.","Once the template is deployed on AWS, return to the Baselime console and refresh the page. You should see the newly connected AWS environment in the list of connected environment.","Within minutes telemetry data from your AWS environment should start displaying in the events streams in the Baselime web console."]},{"i":"how-hard-is-it-to-remove-baselime-from-my-aws-account","l":"How hard is it to remove Baselime from my AWS account?","p":["If you decide to remove Baselime from your AWS account, delete the CloudFormation template Baselime creates on your AWS account. That's all, all resources Baselime created, including the instrumentation layers, will be removed."]},{"i":"does-baselime-automatically-recognise-new-functions-and-services","l":"Does Baselime automatically recognise new functions and services?","p":["Yes, when you deploy new serverless functions and services to your cloud infrastructure, Baselime automatically detects them and starts ingesting logs, metrics and traces from those function. To add OpenTelemetry tracing, add the baselime:tracing tag to your new functions and set it to true."]},{"i":"does-baselime-have-an-impact-on-my-aws-bill","l":"Does Baselime have an impact on my AWS bill?","p":["Baselime relies on a few AWS resources in your AWS account, most notably:","Amazon CloudWatch metrics stream: to enable CloudWatch metrics to be queried using the Baselime query engine","Amazon CloudTrail: to enable CloudTrail events, and also register new subscription filters as soon as new serverless functions or services are created","Amazon Kinesis Data Firehose: To store telemetry data in cold storage in your AWS account","These services may add a minimal cost on your AWS monthly bill. Please refer to the AWS princing calculator for estimates based on your usage."]},{"l":"Troubleshooting","p":["If you encounter any issues or error when connecting your AWS environment, please don't hesitate to contact us, or join our Slack community where we are always available to support."]},{"l":"CloudFormation Template","p":["The CloudFormation template is open-source and available here."]},{"l":"Your data","p":["Once connected, Baselime will automatically ingest data from your AWS environment. This includes:","AWS Lambda Logs","Amazon API Gateway Logs","Amazon Cloudtrail Logs","Amazon Cloudwatch Metrics","Amazon ECS Logs (through fluentd)","Open Telemetry Metrics","AWS X-Ray Traces","Once ingested, the telemetry data is streamed through a Kinesis Firehose to an Amazon S3 bucket in your AWS account for cold storage. There you can access the raw data and use it for your own purposes.","The default retention period of the telemetry data in your bucket is set to 180 days by default."]}],[{"l":"API Integration","p":["Integrate with Baselime to programatically interact with Baselime.","The Baselime API Integration enable the creation of appplications that can interact with Baselime's observability platofrm on behalf of developers."]},{"l":"Getting Started","p":["To create an API integration, get in touch with the Baselime Team via email at techies@baselime.io.","Provide the following details:","Field","Description","Integation Name","The name of the your application","A short description of your application","Logo Icon","A .svg file for the icon of your application","Redirect URL","The URL to redirect developers after they install your integration on Baselime.","The Baselime team will create an your application integration and provide you with unique Client ID and a Client secret. The Client ID is required to for developers to install your integration on Baselime. The Client Secret is necessary for authenticating developers from Baselime in your application.","Your integration will be available at https://console.baselime.io/integrations/your-client-id.","A Baselime Integration"]},{"l":"OAuth Authentication","p":["Once a developer installs your integration on Baselime, they will be redirected to the Redirect URL of your integration, with a temporary authorization code appended to the query string parameters of the URL, such as https://your-redirect-url?code=temporary-auth-code.","The temporary authorization code is valid for 3 minutes."]},{"l":"Request an Access Token","p":["Once the developer is redirected to your provided Redirect URL, use the temporary authorization code to retrieve a short-lived access token for first-time access.","Send a POST request to the token endpoint URL","Set the Content-Type header to applications/json","Add a HTTP Body containing the Client ID and Client Secret along with your Redirect URL, the temporary authorization code and the grantType parameter set to authorization_code.","The response will return an Access Token valid for 24 hours."]},{"l":"Request a Refresh Token","p":["The response to theaccess token call also includes a long-lived Refresh Token. Use the refresh token to request a new Access Token when the access token expires. To generate a new Access Token using the Refresh Token, send a POST request to the token endpoint URL, add the Refresh Token to the request body and change the grantType parameter to refresh_token.","The response will return a new Access Token valid for 24 hours."]},{"l":"Using the API","p":["To enable sending events from your application to Baselime, it's necessary to obtain a public API key from the developer Baselime account."]},{"l":"Request a Public API Key","p":["In Baselime, each public API key is linked to an environment. This ensure the public API key can be used to send events to a single environment.","Use the list environments endpoint to list all the environments using the Access Token.","Send a GET request to the environments endpoint URL","Set the Content-Type header to applications/json","Set the Authorization header to Bearer ACCESS_TOKEN. Replace ACCESS_TOKEN with the Access Token obtained during authentication","The response will return an array containing the list of environments the developer has access to in their Baselime account. Each environment will be composed of:","workspaceId: The ID of the workspace that the environment is a part of.","environmentId: The ID of environment.","apiKey: A public API key that can be used to send events to the environment."]},{"l":"Send events to Baselime","p":["Once you have obtained the public API for an environment, it can be used to send events to Baselime, either using the Events API or the OpenTelemetry API."]}]]